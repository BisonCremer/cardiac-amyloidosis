{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/blue/ferrallm/mcremer/cardiac-amyloidosis/026_SVM_mistic2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "starting_directory = os.getcwd()\n",
    "print(os.getcwd())\n",
    "\n",
    "new_dirrectory = '/blue/ferrallm/mcremer/CardiacAmyloidosisMultipleMyeloma'\n",
    "os.chdir(new_dirrectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/Users/c.kieslich/Box Sync/Research/featureSelection/')\n",
    "\n",
    "from mistic.svmSet import svmSet\n",
    "from mistic.cvSet import cvSet \n",
    "from mistic.utility import combined_rank, kernelWrapper, score_svc, perDiff, paramSet\n",
    "\n",
    "import matplotlib.pyplot as plt   \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some functions I wrote to help with exporting data\n",
    "def outputToExcel(df_data, fileName_header, fileName_Common, fileName_suffix,\n",
    "                  parent_dir, folderName, sheetName):\n",
    "    fileName = fileName_header + fileName_Common + fileName_suffix\n",
    "    outfile_extension = '.xlsx'\n",
    "    outfile_boxplts = fileName + outfile_extension\n",
    "    path_out= os.path.join(parent_dir, folderName, outfile_boxplts)\n",
    "\n",
    "    if os.path.exists(path_out):\n",
    "            #if old sheet\n",
    "            with pd.ExcelWriter(path_out, mode = 'a', if_sheet_exists = 'overlay') as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True)\n",
    "    else: \n",
    "            #new sheet\n",
    "            with pd.ExcelWriter(path_out) as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True) #if new sheet\n",
    "    \n",
    "def outputFiguresPath(fileName_header, fileName_mid, fileName_suff, parent_dir, folderName):\n",
    "        fileName_header = str(fileName_header)\n",
    "        fileName_mid = str(fileName_mid)\n",
    "        fileName_suff = str(fileName_suff)\n",
    "\n",
    "        #cleaning the input to prevent addition of / to the directory\n",
    "        fileName_header = fileName_header.replace(\"/\", \"-\")\n",
    "        fileName_mid = fileName_mid.replace(\"/\", \"-\")\n",
    "        fileName_suff = fileName_suff.replace(\"/\", \"-\")\n",
    "\n",
    "        fileName = fileName_header + fileName_mid +fileName_suff\n",
    "        out_filename = fileName + '.tif'\n",
    "        new_filepath = os.path.join(parent_dir, folderName, out_filename)\n",
    "        #the output path can be used to save the figure\n",
    "        return new_filepath\n",
    "        # plt.savefig(new_filepath, bbox_inches = 'tight')\n",
    "\n",
    "def makeFolderPathForData(parent_dir, folderName_header, folderName_common, folderName_suffix):\n",
    "    #makes a new directory for your files\n",
    "    #returns the folder name for use in other functions\n",
    "    folderName = folderName_header + folderName_common + folderName_suffix\n",
    "    path = os.path.join(parent_dir,folderName)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return folderName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# directory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is written to work out of the blue folder on hpg \n",
    "\n",
    "#for file outputs\n",
    "fileName_header = \"Mistic2_descOnly\" #what data did you put in\n",
    "fileName_common = \"_linear\" #what was performed on the data, for figures, this may be added to\n",
    "fileName_suffix = \"_241118_v1\" #date and versioning\n",
    "\n",
    "saving_dirrectory = \"012 Processed Data\"\n",
    "makingFolder = makeFolderPathForData(parent_dir= saving_dirrectory, folderName_header= \"Mistic2_descOnly_linear_\", folderName_common= \"241118_\", \n",
    "                                     folderName_suffix= \"v1\")\n",
    "dataFrameFolderOut =  makingFolder #\"SVM_Mistic_Output_2024-07-19_v2\"\n",
    "pickleFolderOut = makingFolder\n",
    "\n",
    "figDirectory = \"012 Processed Data\"\n",
    "figFolder = makingFolder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of SVM \n",
    "red_factor = 0.05\n",
    "\n",
    "#cross validation and splitting \n",
    "test_size_numb = 1/5\n",
    "numb_sets = 5\n",
    "\n",
    "C_range = [2**x for x in range(-2,5)]\n",
    "# gamma_range = [2**x for x in range(-9,1)]\n",
    "\n",
    "\n",
    "kernel_type = \"linear\"\n",
    "\n",
    "rank_weights = [0,0.25,0.50,0.75,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFileName = \"AL-KnownPts_CompLabswoEcho_descOnly_1Sheet_20241018_v1.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "dataTable = pd.read_excel(dataFileName, header = 0) #the dataset we are using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling data and defining test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to drop from the x data (samples and features)\n",
    "x_columns_toDrop = ['DeID', 'Amyloid Status_yes', 'Amyloid Status_no', \"Amyloid Status_unk\"]\n",
    "\n",
    "\n",
    "#columns to use for the y data \n",
    "y_column_Classification = 'Amyloid Status_yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataTable.copy()\n",
    "X.drop(columns=x_columns_toDrop,inplace=True)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_all = scaler.transform(X)\n",
    "y_all = dataTable[y_column_Classification]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    stratify = y_all, \n",
    "                                                    random_state= 0, \n",
    "                                                    test_size= test_size_numb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_set = cvSet(X = X_train, y = y_train.values)\n",
    "cv_set.classification(num_sets = numb_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initiallize SVC and parameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel = 'precomputed', class_weight=\"balanced\", probability=False, tol = 1e-12, max_iter=100000)\n",
    "\n",
    "\n",
    "parameter_grid = []\n",
    "for cost in C_range:\n",
    "    parameter_grid.append(paramSet(model={\"C\": cost},kernel={}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank weight: 0.00\n",
      "Number of Features: 329, Score: 0.666\n",
      "Number of Features: 312, Score: 0.646\n",
      "Number of Features: 296, Score: 0.573\n",
      "Number of Features: 281, Score: 0.627\n",
      "Number of Features: 266, Score: 0.624\n",
      "Number of Features: 252, Score: 0.635\n",
      "Number of Features: 239, Score: 0.676\n",
      "Number of Features: 227, Score: 0.677\n",
      "Number of Features: 215, Score: 0.634\n",
      "Number of Features: 204, Score: 0.634\n",
      "Number of Features: 193, Score: 0.655\n",
      "Number of Features: 183, Score: 0.644\n",
      "Number of Features: 173, Score: 0.666\n",
      "Number of Features: 164, Score: 0.666\n",
      "Number of Features: 155, Score: 0.631\n",
      "Number of Features: 147, Score: 0.642\n",
      "Number of Features: 139, Score: 0.607\n",
      "Number of Features: 132, Score: 0.581\n",
      "Number of Features: 125, Score: 0.527\n",
      "Number of Features: 118, Score: 0.527\n",
      "Number of Features: 112, Score: 0.494\n",
      "Number of Features: 106, Score: 0.547\n",
      "Number of Features: 100, Score: 0.548\n",
      "Number of Features: 94, Score: 0.542\n",
      "Number of Features: 89, Score: 0.493\n",
      "Number of Features: 84, Score: 0.554\n",
      "Number of Features: 79, Score: 0.626\n",
      "Number of Features: 75, Score: 0.633\n",
      "Number of Features: 71, Score: 0.640\n",
      "Number of Features: 67, Score: 0.600\n",
      "Number of Features: 63, Score: 0.600\n",
      "Number of Features: 59, Score: 0.699\n",
      "Number of Features: 56, Score: 0.699\n",
      "Number of Features: 53, Score: 0.699\n",
      "Number of Features: 50, Score: 0.710\n",
      "Number of Features: 47, Score: 0.721\n",
      "Number of Features: 44, Score: 0.690\n",
      "Number of Features: 41, Score: 0.799\n",
      "Number of Features: 38, Score: 0.810\n",
      "Number of Features: 36, Score: 0.789\n",
      "Number of Features: 34, Score: 0.789\n",
      "Number of Features: 32, Score: 0.775\n",
      "Number of Features: 30, Score: 0.795\n",
      "Number of Features: 28, Score: 0.775\n",
      "Number of Features: 26, Score: 0.789\n",
      "Number of Features: 24, Score: 0.789\n",
      "Number of Features: 22, Score: 0.819\n",
      "Number of Features: 20, Score: 0.789\n",
      "Number of Features: 18, Score: 0.870\n",
      "Number of Features: 17, Score: 0.863\n",
      "Number of Features: 16, Score: 0.907\n",
      "Number of Features: 15, Score: 0.882\n",
      "Number of Features: 14, Score: 0.887\n",
      "Number of Features: 13, Score: 0.907\n",
      "Number of Features: 12, Score: 0.929\n",
      "Number of Features: 11, Score: 0.929\n",
      "Number of Features: 10, Score: 0.903\n",
      "Number of Features: 9, Score: 0.912\n",
      "Number of Features: 8, Score: 0.912\n",
      "Number of Features: 7, Score: 0.912\n",
      "Number of Features: 6, Score: 0.887\n",
      "Number of Features: 5, Score: 0.907\n",
      "Number of Features: 4, Score: 0.907\n",
      "Number of Features: 3, Score: 0.789\n",
      "Number of Features: 2, Score: 0.669\n",
      "Number of Features: 1, Score: 0.669\n",
      "Rank weight: 0.25\n",
      "Number of Features: 329, Score: 0.666\n",
      "Number of Features: 312, Score: 0.677\n",
      "Number of Features: 296, Score: 0.677\n",
      "Number of Features: 281, Score: 0.688\n",
      "Number of Features: 266, Score: 0.676\n",
      "Number of Features: 252, Score: 0.717\n",
      "Number of Features: 239, Score: 0.687\n",
      "Number of Features: 227, Score: 0.687\n",
      "Number of Features: 215, Score: 0.687\n",
      "Number of Features: 204, Score: 0.709\n",
      "Number of Features: 193, Score: 0.698\n",
      "Number of Features: 183, Score: 0.698\n",
      "Number of Features: 173, Score: 0.740\n",
      "Number of Features: 164, Score: 0.740\n",
      "Number of Features: 155, Score: 0.671\n",
      "Number of Features: 147, Score: 0.648\n",
      "Number of Features: 139, Score: 0.740\n",
      "Number of Features: 132, Score: 0.770\n",
      "Number of Features: 125, Score: 0.750\n",
      "Number of Features: 118, Score: 0.728\n",
      "Number of Features: 112, Score: 0.738\n",
      "Number of Features: 106, Score: 0.750\n",
      "Number of Features: 100, Score: 0.750\n",
      "Number of Features: 94, Score: 0.760\n",
      "Number of Features: 89, Score: 0.742\n",
      "Number of Features: 84, Score: 0.790\n",
      "Number of Features: 79, Score: 0.850\n",
      "Number of Features: 75, Score: 0.850\n",
      "Number of Features: 71, Score: 0.848\n",
      "Number of Features: 67, Score: 0.766\n",
      "Number of Features: 63, Score: 0.742\n",
      "Number of Features: 59, Score: 0.675\n",
      "Number of Features: 56, Score: 0.705\n",
      "Number of Features: 53, Score: 0.727\n",
      "Number of Features: 50, Score: 0.737\n",
      "Number of Features: 47, Score: 0.748\n",
      "Number of Features: 44, Score: 0.759\n",
      "Number of Features: 41, Score: 0.779\n",
      "Number of Features: 38, Score: 0.779\n",
      "Number of Features: 36, Score: 0.738\n",
      "Number of Features: 34, Score: 0.738\n",
      "Number of Features: 32, Score: 0.806\n",
      "Number of Features: 30, Score: 0.831\n",
      "Number of Features: 28, Score: 0.780\n",
      "Number of Features: 26, Score: 0.769\n",
      "Number of Features: 24, Score: 0.799\n",
      "Number of Features: 22, Score: 0.780\n",
      "Number of Features: 20, Score: 0.791\n",
      "Number of Features: 18, Score: 0.852\n",
      "Number of Features: 17, Score: 0.832\n",
      "Number of Features: 16, Score: 0.833\n",
      "Number of Features: 15, Score: 0.833\n",
      "Number of Features: 14, Score: 0.842\n",
      "Number of Features: 13, Score: 0.842\n",
      "Number of Features: 12, Score: 0.827\n",
      "Number of Features: 11, Score: 0.847\n",
      "Number of Features: 10, Score: 0.855\n",
      "Number of Features: 9, Score: 0.847\n",
      "Number of Features: 8, Score: 0.840\n",
      "Number of Features: 7, Score: 0.836\n",
      "Number of Features: 6, Score: 0.828\n",
      "Number of Features: 5, Score: 0.819\n",
      "Number of Features: 4, Score: 0.790\n",
      "Number of Features: 3, Score: 0.830\n",
      "Number of Features: 2, Score: 0.662\n",
      "Number of Features: 1, Score: 0.644\n",
      "Rank weight: 0.50\n",
      "Number of Features: 329, Score: 0.666\n",
      "Number of Features: 312, Score: 0.677\n",
      "Number of Features: 296, Score: 0.677\n",
      "Number of Features: 281, Score: 0.677\n",
      "Number of Features: 266, Score: 0.688\n",
      "Number of Features: 252, Score: 0.700\n",
      "Number of Features: 239, Score: 0.717\n",
      "Number of Features: 227, Score: 0.728\n",
      "Number of Features: 215, Score: 0.740\n",
      "Number of Features: 204, Score: 0.762\n",
      "Number of Features: 193, Score: 0.751\n",
      "Number of Features: 183, Score: 0.785\n",
      "Number of Features: 173, Score: 0.785\n",
      "Number of Features: 164, Score: 0.785\n",
      "Number of Features: 155, Score: 0.785\n",
      "Number of Features: 147, Score: 0.796\n",
      "Number of Features: 139, Score: 0.796\n",
      "Number of Features: 132, Score: 0.796\n",
      "Number of Features: 125, Score: 0.807\n",
      "Number of Features: 118, Score: 0.848\n",
      "Number of Features: 112, Score: 0.848\n",
      "Number of Features: 106, Score: 0.862\n",
      "Number of Features: 100, Score: 0.848\n",
      "Number of Features: 94, Score: 0.849\n",
      "Number of Features: 89, Score: 0.865\n",
      "Number of Features: 84, Score: 0.885\n",
      "Number of Features: 79, Score: 0.885\n",
      "Number of Features: 75, Score: 0.885\n",
      "Number of Features: 71, Score: 0.885\n",
      "Number of Features: 67, Score: 0.899\n",
      "Number of Features: 63, Score: 0.885\n",
      "Number of Features: 59, Score: 0.885\n",
      "Number of Features: 56, Score: 0.885\n",
      "Number of Features: 53, Score: 0.905\n",
      "Number of Features: 50, Score: 0.905\n",
      "Number of Features: 47, Score: 0.874\n",
      "Number of Features: 44, Score: 0.855\n",
      "Number of Features: 41, Score: 0.883\n",
      "Number of Features: 38, Score: 0.883\n",
      "Number of Features: 36, Score: 0.918\n",
      "Number of Features: 34, Score: 0.918\n",
      "Number of Features: 32, Score: 0.880\n",
      "Number of Features: 30, Score: 0.938\n",
      "Number of Features: 28, Score: 0.949\n",
      "Number of Features: 26, Score: 0.932\n",
      "Number of Features: 24, Score: 0.980\n",
      "Number of Features: 22, Score: 0.969\n",
      "Number of Features: 20, Score: 0.969\n",
      "Number of Features: 18, Score: 1.000\n",
      "Number of Features: 17, Score: 0.969\n",
      "Number of Features: 16, Score: 0.969\n",
      "Number of Features: 15, Score: 0.980\n",
      "Number of Features: 14, Score: 0.986\n",
      "Number of Features: 13, Score: 0.966\n",
      "Number of Features: 12, Score: 0.969\n",
      "Number of Features: 11, Score: 0.969\n",
      "Number of Features: 10, Score: 0.980\n",
      "Number of Features: 9, Score: 1.000\n",
      "Number of Features: 8, Score: 1.000\n",
      "Number of Features: 7, Score: 1.000\n",
      "Number of Features: 6, Score: 0.947\n",
      "Number of Features: 5, Score: 0.980\n",
      "Number of Features: 4, Score: 1.000\n",
      "Number of Features: 3, Score: 0.769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_set_ranks = []\n",
    "for i in range(len(rank_weights)):\n",
    "    print(f\"Rank weight: {rank_weights[i]:.2f}\")\n",
    "    svm_set_ranks.append(svmSet(svc, cv_set,\n",
    "                                score_method = score_svc().score,\n",
    "                                kernel = kernelWrapper(type = kernel_type),\n",
    "                                separate_feature_sets = False,\n",
    "                                separate_parameters = False,\n",
    "                                sparse_kernel_matrix = False))\n",
    "\n",
    "    svm_set_ranks[i].greedy_backward_selection(parameter_grid = parameter_grid,\n",
    "                                           reduction_factor = red_factor,\n",
    "                                           feature_ranker = combined_rank(weight=rank_weights[i]).compute,\n",
    "                                           set_for_rank = \"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pickling stage here so that you can use this data for easy replotting\n",
    "\n",
    "#if not already pickled use this block\n",
    "pickle_file_name = 'svmsetsPickle_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(svm_set_ranks, pickle_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path_file = pickle_filePath #file path from the 014_mistic folder onwards through file name\n",
    "pickle_file = open(pickle_path_file, 'rb')\n",
    "svm_set_ranks_2 = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 and AUC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(len(rank_weights)):\n",
    "    svm_set_ranks[i].plot_performance(metric=\"auc\")\n",
    "\n",
    "plt.legend(labels=rank_weights)\n",
    "ax.set_title(\"AUC vs Features\")\n",
    "\n",
    "#saving figure\n",
    "figCommon = fileName_common + \"_AUC\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(len(rank_weights)):\n",
    "    svm_set_ranks[i].plot_performance(metric=\"f1\")\n",
    "\n",
    "plt.legend(labels=rank_weights)\n",
    "ax.set_title(\"F1 vs Features\")\n",
    "\n",
    "#saving figure\n",
    "figCommon = fileName_common + \"_F1\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(len(rank_weights)):\n",
    "    svm_set_ranks[i].plot_performance(metric=\"score\")\n",
    "\n",
    "plt.legend(labels=rank_weights)\n",
    "ax.set_title(\"Score vs Features\")\n",
    "\n",
    "#saving figure\n",
    "figCommon = fileName_common + \"_Score\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# picking best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_score = []\n",
    "for i in range(len(rank_weights)):\n",
    "    enrich_score.append(svm_set_ranks[i].enrichment_score())\n",
    "\n",
    "# selected_run = 4 \n",
    "selected_run = enrich_score.index(max(enrich_score))\n",
    "\n",
    "enrich_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm_set_ranks[selected_run].performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "\n",
    "for i in range(len(rank_weights)):\n",
    "    score_list.append(svm_set_ranks[i].performance_['score'])\n",
    "\n",
    "maxScore = max(score_list)\n",
    "topModelIndex = score_list.index(maxScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "\n",
    "for i in range(len(rank_weights)):\n",
    "    #collecting the performance as a dataframe\n",
    "    df_bestPerformance = pd.DataFrame.from_dict(svm_set_ranks[i].performance_, orient = 'index')\n",
    "    outputToExcel(df_data=df_bestPerformance, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "                folderName= dataFrameFolderOut, sheetName= str(rank_weights[i]).replace(\".\", \"\") + \"_best model perf\")\n",
    "\n",
    "\n",
    "    df_bestFeatures= pd.DataFrame(list(X.columns[svm_set_ranks[i].features]))\n",
    "    #saving the best features\n",
    "    outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "                folderName= dataFrameFolderOut, sheetName= str(rank_weights[i]).replace(\".\",\"\") + \"_features\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(len(rank_weights)): \n",
    "#     # print(\"test\")\n",
    "#     print(\"weight \" , str(rank_weights[i]) , \" :\" ,svm_set_ranks[i].performance_ , '\\n')\n",
    "#     print(\"features: \", \"\\n\", list(X.columns[svm_set_ranks[i].features]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 1\n",
    "for i in range(len(rank_weights)):\n",
    "    if iterator == 1:\n",
    "        #create the df_performance and collect the performance information\n",
    "        df_performance = pd.DataFrame.from_dict(svm_set_ranks[i].performance_, orient = 'index', columns = [str(rank_weights[i])]).T\n",
    "\n",
    "        #create feature list dataframe \n",
    "        df_features = pd.DataFrame(list(X.columns[svm_set_ranks[i].features]), columns=[str(rank_weights[i])])\n",
    "        iterator = iterator + 1 #to increment\n",
    "    else:\n",
    "        #collect the data and add it to the existing frames\n",
    "        df_temp_perf = pd.DataFrame.from_dict(svm_set_ranks[i].performance_, orient = 'index', columns = [str(rank_weights[i])]).T\n",
    "        df_temp_features = pd.DataFrame(list(X.columns[svm_set_ranks[i].features]), columns=[str(rank_weights[i])])\n",
    "        #concatinate with pervious\n",
    "        df_performance = pd.concat([df_performance, df_temp_perf], axis =0)\n",
    "        df_features = pd.concat([df_features, df_temp_features], axis = 1)\n",
    "        iterator = iterator + 1\n",
    "\n",
    "#saving the features and performance\n",
    "outputToExcel(df_data=df_performance, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "            folderName= dataFrameFolderOut, sheetName= \"concat_best model perf\")\n",
    "\n",
    "outputToExcel(df_data=df_features, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "            folderName= dataFrameFolderOut, sheetName= \"concat_features\")\n",
    "\n",
    "iterator = 1\n",
    "dict_blindprediction = {} #index is the weight\n",
    "for i in range(len(rank_weights)):\n",
    "    decision_values = svm_set_ranks[i].decision_function(X_test)\n",
    "    y_pred = svm_set_ranks[i].predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    specificity = tn/(tn + fp)\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    auc = roc_auc_score(y_test, decision_values)\n",
    "\n",
    "    dict_temp_blindpred = {\"f1\": f1, 'auc': auc, 'true neg': tn, 'false pos': fp, 'false neg': fn, 'true pos': tp,\n",
    "                           'precision or PPV': precision, 'recall or TPR': recall, 'specificity or TNR': specificity}\n",
    "    if iterator == 1:\n",
    "        df_blindprediction = pd.DataFrame.from_dict(data = dict_temp_blindpred, orient = 'index', columns = [str(rank_weights[i])]).T\n",
    "        iterator = iterator +1\n",
    "    else:\n",
    "        df_temp_blindpred = pd.DataFrame.from_dict(data = dict_temp_blindpred, orient = 'index', columns = [str(rank_weights[i])]).T\n",
    "        df_blindprediction = pd.concat([df_blindprediction, df_temp_blindpred], axis = 0)\n",
    "        iterator = iterator + 1\n",
    "    # print(df_temp_blindpred)\n",
    "    # dict_blindprediction[str(rank_weights[i])] = df_temp_blindpred\n",
    "\n",
    "# df_blindprediction = pd.DataFrame.from_dict(dict_blindprediction, orient= 'index')\n",
    "outputToExcel(df_data=df_blindprediction, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "            folderName= dataFrameFolderOut, sheetName= \"concat_blindprediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blindprediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots for best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pair plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from seaborn import pairplot, clustermap, load_dataset\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "palette = {np.int64(1) :'red', np.int64(0): 'blue'} #our data is of int64\n",
    "\n",
    "# selected_model = 0\n",
    "top_features = X.columns[svm_set_ranks[selected_run].sorted_features.astype(int)[0:3]].values\n",
    "fig = pairplot(dataTable[np.append(top_features, y_column_Classification)],\n",
    "         hue=y_column_Classification, corner=True, palette=palette)\n",
    "fig.fig.suptitle(f\"Rank weight: {rank_weights[selected_run]:.2f}\", y=1.08)\n",
    "\n",
    "#saving figure\n",
    "figCommon = fileName_common + str(rank_weights[selected_run]).replace(\".\", \"\") + \"_pairplot\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(dataTable, x=top_features[0], y=top_features[1], z=top_features[2],\n",
    "          color=y_column_Classification)\n",
    "fig.update_traces(marker_size = 4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## integrated gradients attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list, fcluster\n",
    "\n",
    "linkMeth = \"average\"\n",
    "\n",
    "IG = svm_set_ranks[selected_run].integrated_gradient(X_test)\n",
    "\n",
    "IGtable = pd.DataFrame(IG,columns=X.columns[svm_set_ranks[selected_run].features])\n",
    "\n",
    "distMatCol = perDiff(IGtable)\n",
    "hcCol = linkage(distMatCol, method=linkMeth,optimal_ordering=True)\n",
    "\n",
    "tr_IGtable = IGtable.transpose()\n",
    "distMatRow = perDiff(tr_IGtable)\n",
    "hcRow = linkage(distMatRow, method=linkMeth,optimal_ordering=True)\n",
    "\n",
    "color_val = max(np.abs((np.mean(IG)-np.std(IG), np.mean(IG)+np.std(IG))))\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "fig = clustermap(IGtable, \n",
    "           yticklabels=False,\n",
    "           cmap=\"vlag\", vmin=-color_val, vmax=color_val,\n",
    "           row_linkage=hcRow, col_linkage=hcCol, \n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(0))+0] for l in y_test])\n",
    "\n",
    "#saving figure\n",
    "figCommon = fileName_common + str(rank_weights[selected_run]).replace(\".\", \"\") + \"_IGheatmap\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list, fcluster\n",
    "\n",
    "# linkMeth = \"average\"\n",
    "\n",
    "# IG = svm_set_ranks[selected_run].integrated_gradient(X_all)\n",
    "\n",
    "# IGtable = pd.DataFrame(IG,columns=X.columns[svm_set_ranks[selected_run].features])\n",
    "\n",
    "# distMatCol = perDiff(IGtable)\n",
    "# hcCol = linkage(distMatCol, method=linkMeth,optimal_ordering=True)\n",
    "\n",
    "# tr_IGtable = IGtable.transpose()\n",
    "# distMatRow = perDiff(tr_IGtable)\n",
    "# hcRow = linkage(distMatRow, method=linkMeth,optimal_ordering=True)\n",
    "\n",
    "# color_val = max(np.abs((np.mean(IG)-np.std(IG), np.mean(IG)+np.std(IG))))\n",
    "\n",
    "# #fig, ax = plt.subplots()\n",
    "# fig = clustermap(IGtable, \n",
    "#            yticklabels=False,\n",
    "#            cmap=\"vlag\", vmin=-color_val, vmax=color_val,\n",
    "#            row_linkage=hcRow, col_linkage=hcCol, \n",
    "#            row_colors=[[\"red\",\"blue\"][int(l==np.int64(0))+0] for l in y_test])\n",
    "\n",
    "# #saving figure\n",
    "# figCommon = fileName_common + str(rank_weights[selected_run]).replace(\".\", \"\") + \"_Xall_IGheatmap\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# # plt.tight_layout()\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "features = svm_set_ranks[selected_run].features\n",
    "df_X_test = pd.DataFrame(X_test[:,features],columns = IGtable.columns)\n",
    "N = len(IGtable)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    coloraxis = {'colorscale':'Bluered'},\n",
    "    xaxis_title = \"Integrated Gradient\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor=\"black\",\n",
    "    )\n",
    "    \n",
    "fig.update_yaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor=\"black\",\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    ")\n",
    "\n",
    "feature_order = np.argsort(np.sum(abs(IG),axis=0))\n",
    "\n",
    "y_val = 1\n",
    "for f in feature_order:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = IGtable.iloc[:,f], \n",
    "        y = y_val + np.random.rand(N)*0.5 - 0.25,\n",
    "        mode = 'markers',\n",
    "        marker = dict(size=9,\n",
    "                      color = df_X_test.iloc[:,f],\n",
    "                      coloraxis = \"coloraxis\",\n",
    "                     ),\n",
    "        name=IGtable.columns[f],\n",
    "    ))\n",
    "    y_val += 1\n",
    "\n",
    "\n",
    "fig.update_layout(showlegend=False, coloraxis_showscale=True)\n",
    "fig.update_coloraxes(colorbar_showticklabels=False,\n",
    "                    colorbar_title=dict(text=\"Feature Value\",side = \"right\"),\n",
    "                    cmin = -1, cmax = 2)\n",
    "fig.update_yaxes(tickvals=[i for i in range(1,IGtable.shape[1]+1)], ticktext=IGtable.columns[feature_order])\n",
    "fig.show() \n",
    "\n",
    "#saving figure\n",
    "figCommon = fileName_common + str(rank_weights[selected_run]) + \"_attribution\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "#fig.fig.savefig(figPath, bbox_inches = 'tight')\n",
    "#pio.write_image(fig, figPath)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "features = svm_set_ranks[selected_run].features\n",
    "df_X_all = pd.DataFrame(X_all[:,features],columns = IGtable.columns)\n",
    "N = len(IGtable)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    coloraxis = {'colorscale':'Bluered'},\n",
    "    xaxis_title = \"Integrated Gradient\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor=\"black\",\n",
    "    )\n",
    "    \n",
    "fig.update_yaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor=\"black\",\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    ")\n",
    "\n",
    "feature_order = np.argsort(np.sum(abs(IG),axis=0))\n",
    "\n",
    "y_val = 1\n",
    "for f in feature_order:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = IGtable.iloc[:,f], \n",
    "        y = y_val + np.random.rand(N)*0.5 - 0.25,\n",
    "        mode = 'markers',\n",
    "        marker = dict(size=9,\n",
    "                      color = df_X_all.iloc[:,f],\n",
    "                      coloraxis = \"coloraxis\",\n",
    "                     ),\n",
    "        name=IGtable.columns[f],\n",
    "    ))\n",
    "    y_val += 1\n",
    "\n",
    "\n",
    "fig.update_layout(showlegend=False, coloraxis_showscale=True)\n",
    "fig.update_coloraxes(colorbar_showticklabels=False,\n",
    "                    colorbar_title=dict(text=\"Feature Value\",side = \"right\"),\n",
    "                    cmin = -1, cmax = 2)\n",
    "fig.update_yaxes(tickvals=[i for i in range(1,IGtable.shape[1]+1)], ticktext=IGtable.columns[feature_order])\n",
    "fig.show() \n",
    "\n",
    "#saving figure\n",
    "figCommon = fileName_common + str(rank_weights[selected_run]) + \"_Xall_attribution\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "#fig.fig.savefig(figPath, bbox_inches = 'tight')\n",
    "#pio.write_image(fig, figPath)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_1 = list(X.columns[svm_set_ranks[selected_run].features])[0]\n",
    "feat_2 = list(X.columns[svm_set_ranks[selected_run].features])[1]\n",
    "\n",
    "fig = px.scatter(x = df_X_test[feat_1], y = IGtable[feat_1], color = df_X_test[feat_2])\n",
    "fig.update_traces(marker=dict(size=12))\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    coloraxis = {'colorscale':'Bluered'},\n",
    "    xaxis_title = feat_1,\n",
    "    yaxis_title = \"Integrated Gradient for \" + feat_1,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor='lightgrey',\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    "    )\n",
    "    \n",
    "fig.update_yaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor='lightgrey',\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    ")\n",
    "\n",
    "fig.update_coloraxes(colorbar_showticklabels=False,\n",
    "                    colorbar_title=dict(text=feat_2,side = \"right\"),\n",
    "                    cmin = -1, cmax = 2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "figCommon = fileName_common + str(selected_run) + \"_2x2\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_1 = list(X.columns[svm_set_ranks[selected_run].features])[0]\n",
    "feat_2 = list(X.columns[svm_set_ranks[selected_run].features])[1]\n",
    "\n",
    "fig = px.scatter(x = df_X_all[feat_1], y = IGtable[feat_1], color = df_X_all[feat_2])\n",
    "fig.update_traces(marker=dict(size=12))\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    coloraxis = {'colorscale':'Bluered'},\n",
    "    xaxis_title = feat_1,\n",
    "    yaxis_title = \"Integrated Gradient for \" + feat_1,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor='lightgrey',\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    "    )\n",
    "    \n",
    "fig.update_yaxes(\n",
    "    zeroline=True,\n",
    "    zerolinecolor='lightgrey',\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey'\n",
    ")\n",
    "\n",
    "fig.update_coloraxes(colorbar_showticklabels=False,\n",
    "                    colorbar_title=dict(text=feat_2,side = \"right\"),\n",
    "                    cmin = -1, cmax = 2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "figCommon = fileName_common + str(selected_run) + \"_Xall_2x2\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcremerConda_2024-07-15_v1",
   "language": "python",
   "name": "mcremerconda_2024-07-15_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
