{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class patient:\n",
    "    def __init__(self, filepath, input_fileName, lengthPtID):\n",
    "        ptID = input_fileName[:lengthPtID]\n",
    "        self.ptID = ptID\n",
    "        self.fileName = input_fileName\n",
    "        #find the demographics in one of two sheets\n",
    "        # directory = os.getcwd()\n",
    "        file_adds = filepath + '/' + input_fileName\n",
    "        file = pd.ExcelFile(file_adds)\n",
    "        sheet_Names = file.sheet_names\n",
    "        if 'Cancer_Registery Data' in sheet_Names:\n",
    "            #do the thing for getting patient info\n",
    "            df = pd.read_excel(input_fileName, sheet_name= 'Cancer_Registery Data')\n",
    "            self.ptDemographics = df\n",
    "            self.amyloid_status = df.at[0,\"Amyloid Status\"]\n",
    "            self.survival = df.at[0,\"Survival Time (Months)\"]\n",
    "            self.ageDx = df.at[0,\"Age At Diagnosis\"] \n",
    "            self.sex = df.at[0,\"Gender Cancer Registry\"]\n",
    "            self.vitalStatus = df.at[0, \"Vital Status Cancer Registry\"]\n",
    "            self.dx = df.at[0, \"Histology\"]\n",
    "\n",
    "        elif '30 Cerner Patients ' in sheet_Names:\n",
    "            #do the thing for getting patient info\n",
    "            df = pd.read_excel(input_fileName, sheet_name= '30 Cerner Patients ')\n",
    "            self.ptDemographics = df\n",
    "            self.amyloid_status = df.at[0,\"Amyloid Status\"]\n",
    "            self.survival = df.at[0,\"Survival Time (months)\"]\n",
    "            self.ageDx = df.at[0,\"Age At Diagnosis\"] \n",
    "            self.sex = df.at[0,\"Gender Cerner\"]\n",
    "            self.vitalStatus = df.at[0, \"Vital Status (Cerner)\"]\n",
    "            self.dx = df.at[0, \"Primary Site\"]\n",
    "\n",
    "\n",
    "        else: print(\"no patient identifying information\")\n",
    "\n",
    "        #now iterate through the list of sheets to import the patient data \n",
    "        if 'Labs' in sheet_Names:\n",
    "            self.labsData = pd.read_excel(input_fileName, sheet_name= 'Labs')\n",
    "        else: self.labsData = False\n",
    "        \n",
    "        if 'amyloid in subject' in sheet_Names:\n",
    "            self.echoData = pd.read_excel(input_fileName, sheet_name= 'amyloid in subject')\n",
    "        else: self.echoData = False\n",
    "\n",
    "        if 'ChemoTx' in sheet_Names:\n",
    "            self.ChemoTx = pd.read_excel(input_fileName, sheet_name= 'ChemoTx')\n",
    "        else: self.ChemoTx = False\n",
    "\n",
    "        if 'Hematologic Tx' in sheet_Names:\n",
    "            self.HemeTx = pd.read_excel(input_fileName, sheet_name= 'Hematologic Tx')\n",
    "        else: self.HemeTx = False\n",
    "\n",
    "        if 'Immuno Tx' in sheet_Names:\n",
    "            self.ImmunoTx = pd.read_excel(input_fileName, sheet_name= 'Immuno Tx')\n",
    "        else: self.ImmunoTx = False\n",
    "\n",
    "        if 'Radiation Tx' in sheet_Names:\n",
    "            self.RadTx = pd.read_excel(input_fileName, sheet_name= 'Radiation Tx')\n",
    "        else: self.RadTx = False\n",
    "\n",
    "        if 'Other Tx' in sheet_Names:\n",
    "            self.OtherTx = pd.read_excel(input_fileName, sheet_name = 'Other Tx')\n",
    "        else: self.OtherTx = False\n",
    "\n",
    "        if 'Physican_Notes' in sheet_Names:\n",
    "            self.MDnotes = pd.read_excel(input_fileName, sheet_name= 'Physican_Notes')\n",
    "        else: self.MDnotes = False\n",
    "\n",
    "        #to create a callable list of treatments recieved for which we have data\n",
    "        tx_sheets = ['ChemoTx', 'Hematologic Tx', 'Immuno Tx']\n",
    "        treatmentTypesRecieved = []\n",
    "\n",
    "        for possible in tx_sheets:\n",
    "        \n",
    "            if possible in sheet_Names:\n",
    "                treatmentTypesRecieved.append(possible)\n",
    "        self.txRecieved = treatmentTypesRecieved\n",
    "\n",
    "def FilterList(list, keyWords_primary, keyWords_secondary = [\"Empty\"], omit = [\"Empty\"]):\n",
    "    #store the filtered result\n",
    "    filteredList = []\n",
    "\n",
    "    if keyWords_secondary == [\"Empty\"]:\n",
    "        for c in list: #loop the columns\n",
    "            for buzz in keyWords_primary: #loop the key words\n",
    "                if buzz in c: #if the column contains the key word\n",
    "                    filteredList.append(c) #add the column to the list\n",
    "                    break #do not continue testing primary key words for this column\n",
    "    \n",
    "    else: \n",
    "        for c in list: #loop the columns\n",
    "            for buzz in keyWords_primary: #loop the key words\n",
    "                if buzz in c: #if the column contains the key word\n",
    "                    for secondary in keyWords_secondary:\n",
    "                        if secondary in c:\n",
    "                            filteredList.append(c) #add the column to the list\n",
    "                            break #has been added to list based on passing the seondary \n",
    "                        else:\n",
    "                            pass\n",
    "                    break #do not continue to check primary key words for this column\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "    if omit != [\"Empty\"]: \n",
    "        for x in omit: \n",
    "            for a in filteredList:\n",
    "                if x in a:\n",
    "                    filteredList.remove(a)\n",
    "    \n",
    "    #by iterating through the column names first, we keep the order of the columns\n",
    "\n",
    "    return filteredList \n",
    "\n",
    "#createBinary function\n",
    "def createBinary(df, listOfLabs, timeColumn): \n",
    "    #list of labs needs to match exactly.  \n",
    "    # Filter the dataframe before inputting\n",
    "    #for boolean\n",
    "    df_toBool = df[listOfLabs]\n",
    "    df_bool = df_toBool.notna()\n",
    "    df_asint = df_bool.astype(int)\n",
    "    #add column back for time \n",
    "    df_asint.insert(0, timeColumn, df[timeColumn])\n",
    "    return df_asint\n",
    "\n",
    "def createBinarySum(df, listOfLabs, timeColumn, defaxis):\n",
    "    #list of labs needs to match exactly.  \n",
    "    # Filter the dataframe before inputting\n",
    "    #for boolean\n",
    "    df_toBool = df[listOfLabs]\n",
    "    df_bool = df_toBool.notna()\n",
    "    df_asint = df_bool.astype(int)\n",
    "    #add column back for time \n",
    "    # df_asint.insert(0, timeColumn, df[timeColumn])\n",
    "    #sum across the row\n",
    "    #defaxis = 0 means the columns are preserved \n",
    "    #defaxis =1 means the rows are preserved\n",
    "    df_new_sum = df_asint.sum(axis = defaxis)\n",
    "    return df_new_sum\n",
    "\n",
    "#get list of patients from directory \n",
    "def GetListOfPatientsFromDirectory (directory, fileExtension, fileCommon, lengthID):\n",
    "    #get the directory \n",
    "    listFileNames = os.listdir(directory)\n",
    "    outputList = []\n",
    "    #loop through list of fileNames: \n",
    "    for file in listFileNames:\n",
    "        #id if the file is patient data\n",
    "        if fileCommon in file and file.endswith(fileExtension):\n",
    "            #trim the file name to the pt ID\n",
    "            ptID = file[:lengthID]\n",
    "            outputList.append(ptID)\n",
    "    return outputList\n",
    "\n",
    "\n",
    "def GetListofPTfiles(directory, fileExtension, fileCommon):\n",
    "    listFileNames = os.listdir(directory)\n",
    "    outListFiles = []\n",
    "    #loop through file names\n",
    "    for file in listFileNames:\n",
    "        if fileCommon in file and file.endswith(fileExtension):\n",
    "            outListFiles.append(file)\n",
    "    return outListFiles\n",
    "def getNormalValue(filteredDataColumn, skipValue = 6666):\n",
    "    test = filteredDataColumn\n",
    "    #input is a series\n",
    "    \n",
    "    for entry in test:\n",
    "        if entry != skipValue:\n",
    "            outputValue = entry\n",
    "                # print(\"this is output: \", outputValue)\n",
    "                #set x to True\n",
    "            break\n",
    "        else:\n",
    "            # print(\"entry is blank\")\n",
    "            pass\n",
    "    return outputValue\n",
    "\n",
    "#get amyloid status dictionary inputs, sort ptIDs to lists based on amyloid status \n",
    "def getListSortedByAmyloid(amyloidDictionary, listPositive, listNegative, listOther,\n",
    "                           statusPositive = \"yes\", statusNegative = \"no\"):\n",
    "    for pt in amyloidDictionary.keys():\n",
    "        status = amyloidDictionary[pt]\n",
    "        if status == statusPositive:\n",
    "            listPositive.append(pt)\n",
    "        elif status == statusNegative:\n",
    "            listNegative.append(pt)\n",
    "        else:\n",
    "            listOther.append(pt)\n",
    "    #does not check for double listed patient IDs\n",
    "    \n",
    "#function for masking a dataframe \n",
    "def patientSectionOfFrame(start_frame, column_toMask, ptID):\n",
    "    #ptID is a row parameter in the column_toMask\n",
    "    df_use = start_frame #copy of the frame\n",
    "\n",
    "    #first check if sheet has the column of interest\n",
    "    data_top = list(start_frame.columns) #returns the headers as a list\n",
    "\n",
    "    #determine of the sheet contains the column of interest\n",
    "    if data_top.count(column_toMask) > 0: \n",
    "        #if true, now find if the patient is present\n",
    "        searchForPt = start_frame[column_toMask].str.startswith(ptID).sum() #returns the number of instances of the patient\n",
    "        if searchForPt > 0:\n",
    "            #patient is present \n",
    "            #mask the data for the patient\n",
    "            df_clean = df_use.dropna(subset= [column_toMask]) #removing NA \n",
    "            mask = df_clean[column_toMask].str.startswith(ptID) #masking for the rows where the patient has data\n",
    "            df_sub_tosave = df_clean[mask] #output dataframe filtered for the patient\n",
    "            return df_sub_tosave\n",
    "        else:\n",
    "            #the patient isn't present\n",
    "            # return print(\"The patient \" + ptID + \" is not in \" + sheet_name)\n",
    "            pass\n",
    "    else:\n",
    "        #the column of interest isn't present\n",
    "        # return print(\"The column \" + column_toMask + \" is not in the sheet \" + sheet_name)\n",
    "        pass\n",
    "\n",
    "\n",
    "def outputToExcel(df_data, fileName_header, fileName_Common, fileName_suffix,\n",
    "                  parent_dir, folderName, sheetName):\n",
    "    fileName = fileName_header + fileName_Common + fileName_suffix\n",
    "    outfile_extension = '.xlsx'\n",
    "    outfile_boxplts = fileName + outfile_extension\n",
    "    path_out= os.path.join(parent_dir, folderName, outfile_boxplts)\n",
    "\n",
    "    if os.path.exists(path_out):\n",
    "            #if old sheet\n",
    "            with pd.ExcelWriter(path_out, mode = 'a', if_sheet_exists = 'overlay') as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True)\n",
    "    else: \n",
    "            #new sheet\n",
    "            with pd.ExcelWriter(path_out) as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True) #if new sheet\n",
    "    \n",
    "def outputFiguresPath(fileName_header, fileName_mid, fileName_suff, parent_dir, folderName):\n",
    "        fileName_header = str(fileName_header)\n",
    "        fileName_mid = str(fileName_mid)\n",
    "        fileName_suff = str(fileName_suff)\n",
    "\n",
    "        #cleaning the input to prevent addition of / to the directory\n",
    "        fileName_header = fileName_header.replace(\"/\", \"-\")\n",
    "        fileName_mid = fileName_mid.replace(\"/\", \"-\")\n",
    "        fileName_suff = fileName_suff.replace(\"/\", \"-\")\n",
    "\n",
    "        fileName = fileName_header + fileName_mid +fileName_suff\n",
    "        out_filename = fileName + '.tif'\n",
    "        new_filepath = os.path.join(parent_dir, folderName, out_filename)\n",
    "        #the output path can be used to save the figure\n",
    "        return new_filepath\n",
    "        # plt.savefig(new_filepath, bbox_inches = 'tight')\n",
    "\n",
    "def makeFolderPathForData(parent_dir, folderName_header, folderName_common, folderName_suffix):\n",
    "    #makes a new directory for your files\n",
    "    #returns the folder name for use in other functions\n",
    "    folderName = folderName_header + folderName_common + folderName_suffix\n",
    "    path = os.path.join(parent_dir,folderName)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return folderName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries and dirrectory \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# directory and file configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location of original data\n",
    "starting_directory = os.getcwd()\n",
    "\n",
    "# new_dirrectory = 'C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/data-2024-06-05'\n",
    "# # new_dirrectory = '/blue/ferrallm/mcremer/CardiacAmyloidosisMultipleMyeloma/012 Processed Data'\n",
    "\n",
    "machine_directory = 'C:/Users/mcremer' #the C and path to the project folder\n",
    "# machine_directory = 'C:/Users/maega' #when working from home machine\n",
    "storage_directory = 'UFL Dropbox/Maegan Cremer/research-share/Maegan/Projects' #Local, HPG, or dropbox\n",
    "project_directory = 'Cardiac-Amyloidosis-Multiple-Myeloma' #project folder\n",
    "project_lv2_directory = '012 Processed Data/data-2024-06-05' #deeper part of project folder\n",
    "\n",
    "path = os.path.join(machine_directory, storage_directory, \n",
    "                    project_directory, project_lv2_directory)\n",
    "\n",
    "new_dirrectory = path\n",
    "\n",
    "os.chdir(new_dirrectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updates to directory management\n",
    "machine_directory = 'C:/Users/mcremer' #the C and path to the project folder\n",
    "# machine_directory = 'C:/Users/maega' #when working from home machine\n",
    "storage_directory = 'UFL Dropbox/Maegan Cremer/research-share/Maegan/Projects' #Local, HPG, or dropbox\n",
    "project_directory = 'Cardiac-Amyloidosis-Multiple-Myeloma' #project folder\n",
    "project_lv2_directory = '012 Processed Data' #deeper part of project folder\n",
    "\n",
    "path = os.path.join(machine_directory, storage_directory, \n",
    "                    project_directory, project_lv2_directory)\n",
    "\n",
    "# parent_dir = path\n",
    "outputDir = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderNameHeader = \"DFsForSVM\"\n",
    "folderNameCommon = \"_ALKnown_EchoAdjLabs_top60E\"\n",
    "folderNameSuffix = \"_2024-08-20_v1\"\n",
    "\n",
    "fileNameHeader_1 = \"AL_KnownPts\"\n",
    "fileNameHeader_2 = \"AL_UnknownPts\"\n",
    "fileNameCommon = \"_EchoAdjLabs_top60E\"\n",
    "fileNameSuffix = \"_2024-08-20_v1\"\n",
    "\n",
    "folder_data_out = makeFolderPathForData(parent_dir=outputDir, folderName_header=folderNameHeader, \n",
    "                                        folderName_common=folderNameCommon, folderName_suffix=folderNameSuffix)\n",
    "# outputToExcel(*, fileName_header=fileNameHeader, fileName_Common= fileNameCommon, \n",
    "#               fileName_suffix= fileNameSuffix, folderName = folder_data_out, sheetName= *)\n",
    "\n",
    "# fig_file_out = outputFiguresPath(fileName_header=fileNameHeader, fileName_mid=**, \n",
    "#                                  fileName_suff= fileNameSuffix, parent_dir=parent_dir, folderName=folder_data_out)\n",
    "\n",
    "folderNameOut = folder_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file name suffix \n",
    "outputSheet_Suffix = fileNameSuffix\n",
    "outputSheet_common = fileNameCommon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## penalty scores used throughout the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score assigned to missing values\n",
    "penaltyMissing = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing data from patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing patient data as dictionaries of dataframes\n",
    "\n",
    "#build a dictionary of patients and their values \n",
    "ptFiles = GetListofPTfiles(new_dirrectory, '.xlsx', 'data')\n",
    "\n",
    "patientDictAmyloid = {}\n",
    "patientDictSurvival = {}\n",
    "patientDictLabs = {}\n",
    "patientDictEcho = {}\n",
    "patientDictNotes = {}\n",
    "patientDictDx = {}\n",
    "patientDictVitalStatus = {}\n",
    "patientDictSex = {}\n",
    "patientDictAge = {}\n",
    "patientDictChemo = {}\n",
    "patientDictImmuno = {}\n",
    "patientDictHeme = {}\n",
    "patientDictRad = {}\n",
    "patientDictOther = {}\n",
    "\n",
    "#loop through the listOfPatients \n",
    "for file in ptFiles: \n",
    "    pt = patient(new_dirrectory, file, 4)\n",
    "    patientDictAmyloid[pt.ptID] = pt.amyloid_status\n",
    "    patientDictSurvival[pt.ptID] = pt.survival\n",
    "    patientDictLabs[pt.ptID] = pt.labsData\n",
    "    patientDictEcho[pt.ptID] = pt.echoData\n",
    "    patientDictNotes[pt.ptID] = pt.MDnotes\n",
    "    patientDictDx[pt.ptID] = pt.dx\n",
    "    patientDictVitalStatus[pt.ptID] = pt.vitalStatus\n",
    "    patientDictSex[pt.ptID] = pt.sex\n",
    "    patientDictAge[pt.ptID] = pt.ageDx\n",
    "    patientDictChemo[pt.ptID] = pt.ChemoTx\n",
    "    patientDictImmuno[pt.ptID] = pt.ImmunoTx\n",
    "    patientDictHeme[pt.ptID] = pt.HemeTx\n",
    "    patientDictRad[pt.ptID] = pt.RadTx\n",
    "    patientDictOther[pt.ptID] = pt.OtherTx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort patients by amyloid status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of patients by amyloid status \n",
    "\n",
    "listPositive = []\n",
    "listNegative = []\n",
    "listOther = []\n",
    "\n",
    "getListSortedByAmyloid(patientDictAmyloid, listPositive= listPositive,\n",
    "                       listNegative=listNegative, listOther=listOther)\n",
    "\n",
    "#first make a copy of the list\n",
    "listALKnown = listPositive.copy()\n",
    "#add the negative patients to the list of positive patients\n",
    "listALKnown.extend(listNegative) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting patient demographic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dx_codes = {\n",
    "    \"MGUS\" : 1, \n",
    "    \"MM\" : 2, \n",
    "    \"Multiple Myeloma\" : 2,\n",
    "    \"MULTIPLE MYELOMA\" : 2 \n",
    "    #other values are going to be set to 0\n",
    "}\n",
    "\n",
    "dict_AL_codes = {\n",
    "    \"yes\" : 2, \n",
    "    \"no\" : 1, \n",
    "    \"unk\" : 3,\n",
    "}\n",
    "\n",
    "dict_sex_codes = {\n",
    "    \"Male\" : 0,\n",
    "    \"MALE\": 0, \n",
    "    \"Female\" : 1, \n",
    "    \"FEMALE\" : 1,  \n",
    "}\n",
    "\n",
    "dict_of_codes = {\"AL\": dict_AL_codes, \n",
    "                 \"Dx\": dict_dx_codes, \n",
    "                 \"Sex\": dict_sex_codes}\n",
    "\n",
    "dict_of_data = {\"AL\": patientDictAmyloid, \n",
    "                \"Dx\": patientDictDx, \n",
    "                \"Sex\": patientDictSex}\n",
    "\n",
    "dict_encoded_pt_AL_Dx_sex = {}\n",
    "\n",
    "for ptID in listALKnown:\n",
    "    listPtValues = []\n",
    "    for key in list(dict_of_codes.keys()):\n",
    "        LocalValue = ''\n",
    "        for code in dict_of_codes[key]:\n",
    "            if code in dict_of_data[key][ptID]:\n",
    "                # print(ptID, \" code: \", code)\n",
    "                LocalValue = dict_of_codes[key][code] \n",
    "        if LocalValue == '': \n",
    "            listPtValues.append(0)\n",
    "        else:\n",
    "             listPtValues.append(LocalValue)\n",
    "    # print(\"patient values: \", listPtValues)\n",
    "    dict_encoded_pt_AL_Dx_sex[ptID] = listPtValues\n",
    "\n",
    "df_all_encoded_AL_dx_sex = pd.DataFrame.from_dict(dict_encoded_pt_AL_Dx_sex, orient='index', columns=[\"Amyloid Status\", \"Dx\", \"Sex\"])\n",
    "\n",
    "#getting age and survival \n",
    "df_all_ages = pd.DataFrame.from_dict(patientDictAge, orient= 'index', columns= ['Age'])\n",
    "df_all_survival = pd.DataFrame.from_dict(patientDictSurvival, orient='index', columns= ['Survival (in months)'])\n",
    "\n",
    "#combining for demographics\n",
    "\n",
    "df_all_demographics = pd.concat([df_all_encoded_AL_dx_sex, df_all_ages, df_all_survival], axis= 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter the patient labs to top60E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToUse =[\"Creatinine Result(mg/dL)\", \"Potassium Result(mmol/L)\", \"total CO2 Result\", \"Chloride Result(mmol/L)\", \"Calcium Result(mg/dL)\",\n",
    "               \"Sodium Result(mmol/L)\", \"Glucose Result\", \"BUN Result(mg/dL)\", \"Platelet Count Result(k/uL)\", \"Hemoglobin Result\",\n",
    "               \"MCHC Result\", \"MCV Result\", \"MCH Result(pg)\", \"HCT Result\", \"RBC Result\", \"WBC Result(k/uL)\", \"Albumin Result(gm/dL)\",\n",
    "               \"Neutrophil Result\", \"Monocyte Result\", \"Pct. Neutrophil Result\", \"Pct. Mono Result\", \"Total Serum Protein Result\",\n",
    "               \"Pct. Immature Gran Auto Result\", \"Pct. Immature Gran Auto Result\", \"Nucleated RBC Result\", \"AST Result(U/L)\", \"ALT Result(U/L)\",\n",
    "               \"Serum Electrophoresis Alpha 1 Result\", \"Serum Electrophoresis Alpha 2 Result\", \"Serum Electrophoresis Beta Result\", \n",
    "               \"Serum Electrophoresis Gamma Result\", \"Albumin Electrophoresis Result\", \"LDH Result(U/L)\", \"Kappa Free Light Chains Result (mg/L)\", \n",
    "               \"Beta-2-Microglobulin Result\", \"NT Pro BNP (B-Type Natriuretic Peptide)\", \"Troponin-T\", \"RDW Result\", \"Pct. Nucleated RBC/100 WBC Result\",\n",
    "               \"Bilirubin Result\", \"Ferritin Result(ng/mL)\", \"Serum Immunologic IgG Result\", \"Reticulocyte Percentage Result\", \n",
    "               \"Serum Immunologic IgA Result Value Result\", \"Serum Immunologic IgM Result\", \"Erythrocyte SR Result\", \"Urine Albumin Outcome Result\", \n",
    "               \"B12 Result (pg/mL)\", \"TIBC Result (ug/dL)\", \"Urinalysis Alpha2 Globulin Result\", \"Urinalysis Alpha1 Globulin Result\", \n",
    "               \"Urinalysis Beta Globulin Result\", \"Lymphocyte Result\", \"Eosinophil Result\", \"Basophil Result\", \"Pct. Lymphocyte Result\", \n",
    "               \"Pct. Eosinophil Result\", \"Pct. Basophil Result\", \"Urinalysis M Spike Result\", \"Urinalysis M Spike Percent Result\", \"Serum Electrophoresis M Spike Result\"]\n",
    "# labs atleast 76% filled across all patients.  Addition of serum and urine M spike measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary for the filtered data and the list of columnNames\n",
    "#this enables filtering of the patient data as its own block of code\n",
    "dictOfFilteredLabs = {}\n",
    "\n",
    "#other input values to set outside of loop \n",
    "x_column_name = \"RelTime(Days)\"\n",
    "#creating dictionaries for all patients in the dirrectory \n",
    "\n",
    "#also collects the column names of interest \n",
    "\n",
    "for ptID in listALKnown:\n",
    "    #to collect and filter the patient labs into a dictionary\n",
    "    df_Labs = patientDictLabs[ptID]\n",
    "\n",
    "    orig_columns = df_Labs.columns\n",
    "\n",
    "    #filter the patient labs\n",
    "    # columnNames = FilterList(orig_columns, keyWords_primary = ['Result', 'Troponin-T', 'BNP'],  \n",
    "    #                             omit = ['Method', 'ABO', 'Dohle', \"Toxic Granulation\", \"D Dimer Result\",\n",
    "    #                                     \"Urine Color Result\", \"Urine Leukocyte Esterase Result\",\n",
    "    #                                     \"Urine Nitrite Result\", \"Urinalysis Squamous Epithelial Cells Result (/hpf)\",\n",
    "    #                                     \"(/hpf)\", \"Hep B\", \"Hep B Surf Ag Result\", \"Hep C\", \"Hep C Ab Screen Result\",\n",
    "    #                                     \"Hypersegmentation Result\", \"HCG Result (Serum)\", \"Coombs Test Result\",\n",
    "    #                                     \"HIV Result\"])\n",
    "    columnNames = FilterList(orig_columns, keyWords_primary = columnsToUse,\n",
    "                             omit = ['Method', 'ABO', 'Dohle', \"Toxic Granulation\", \"D Dimer Result\",\n",
    "                                        \"Urine Color Result\", \"Urine Leukocyte Esterase Result\",\n",
    "                                        \"Urine Nitrite Result\", \"Urinalysis Squamous Epithelial Cells Result (/hpf)\",\n",
    "                                        \"(/hpf)\", \"Hep B\", \"Hep B Surf Ag Result\", \"Hep C\", \"Hep C Ab Screen Result\",\n",
    "                                        \"Hypersegmentation Result\", \"HCG Result (Serum)\", \"Coombs Test Result\",\n",
    "                                        \"HIV Result\", \"Urine Glucose Result(mg/dL)\"])\n",
    "    \n",
    "    \n",
    "    testNames = [x_column_name]\n",
    "    testNames.extend(columnNames) #addition of time label\n",
    "\n",
    "\n",
    "    ptLabs_results= df_Labs[testNames] #new data frame of just results\n",
    "\n",
    "    #troponin contains strings which mess up plotting \n",
    "    df_Labs_results_2 = ptLabs_results\n",
    "    # for col in columnNames:\n",
    "    #     df_Labs_results_2[col] = ptLabs_results[col].apply(lambda x: 0 if isinstance(x, str) else x)\n",
    "    df_Labs_results_2[\"Troponin-T\"] = ptLabs_results[\"Troponin-T\"].apply(lambda x: 0 if isinstance(x, str) else x)\n",
    "    df_Labs_results_2[\"NT Pro BNP (B-Type Natriuretic Peptide)\"] = ptLabs_results[\"NT Pro BNP (B-Type Natriuretic Peptide)\"].apply(lambda x: 0 if isinstance(x, str) else x)\n",
    "    # df_Labs_results_2['Anisocytosis Result'] = df_Labs_results_2['Anisocytosis Result'].replace({'1+': 1, '2+': 2,'3+': 3})\n",
    "    # df_Labs_results_2['Macrocytes Result'] = df_Labs_results_2['Macrocytes Result'].replace({'1+': 1, '2+': 2,'3+': 3})\n",
    "\n",
    "    ptLabs_results_2 = df_Labs_results_2\n",
    "    dictOfFilteredLabs[ptID] = ptLabs_results_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect echo dates and convert to days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EchoTimeColumn ='time from diagnosis to first echo (months)'\n",
    "echoDates = {}\n",
    "dict_echoDates_Days = {}\n",
    "for pt in patientDictEcho:\n",
    "    ptEchoData = patientDictEcho[pt]\n",
    "    patientEchoDate = ptEchoData[EchoTimeColumn]\n",
    "    if 'none' not in list(patientEchoDate):\n",
    "        echoDates[pt] = patientEchoDate\n",
    "        #convert from months to days\n",
    "        dict_echoDates_Days[pt] = patientEchoDate * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data nearest to the date of echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat the data into a single sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in missing data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for amyloid status known patients\n",
    "df_ALKnown_summary = pd.concat([df_ALKnown_demographics, \n",
    "                    df_ALKnown_LabFitsLinear, df_ALKnown_LabFitsLinearWB, df_ALKnown_LabFitsQuadForce,\n",
    "                    df_ALKnown_LabFitsExp2Force, df_ALKnown_MDNotesDescriptive, df_AL_known_tx_summary], axis =1 )\n",
    "\n",
    "outputToExcel(df_data = df_ALKnown_summary, fileName_header= \"AL-KnownPts\", fileName_Common= fileNameCommon + \"_1Sheet\", fileName_suffix= outputSheet_Suffix,\n",
    "        parent_dir= outputDir, folderName=folderNameOut, sheetName= \"ALL\")\n",
    "\n",
    "df_ALOther_summary = pd.concat([df_ALOther_demographics, \n",
    "                    df_ALOther_LabFitsLinear, df_ALOther_LabFitsLinearWB, df_ALOther_LabFitsQuadForce,\n",
    "                    df_ALOther_LabFitsExp2Force, df_ALOther_MDNotesDescriptive, df_AL_Unknown_tx_summary], axis =1 )\n",
    "\n",
    "outputToExcel(df_data = df_ALOther_summary, fileName_header= \"AL-UnknownPts\", fileName_Common= fileNameCommon + \"_1Sheet\", fileName_suffix= outputSheet_Suffix,\n",
    "        parent_dir= outputDir, folderName=folderNameOut, sheetName= \"ALL\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
