{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation of Mistic \n",
    "to our binary description of patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/blue/ferrallm/mcremer/cardiac-amyloidosis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "starting_directory = os.getcwd()\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries and dirrectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set dirrectory\n",
    "import os\n",
    "starting_directory = os.getcwd()\n",
    "\n",
    "#helps when fetching the functions and classes from mistic  \n",
    "# new_dirrectory = 'C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Shared-From-DrK/mistic_breast_cancer_example/mistic_breast_cancer_example'\n",
    "new_dirrectory = '/blue/ferrallm/mcremer/CardiacAmyloidosisMultipleMyeloma'\n",
    "os.chdir(new_dirrectory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages/modules\n",
    "import matplotlib.pyplot as plt   \n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import mean \n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from seaborn import clustermap, heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "# Import functions\n",
    "from mistic_v1 import greedy_backward_selection, tuneSVM, compute_SV_feature_importance, compute_counterfactuals #, compute_SV_feature_contribution\n",
    "from mistic_v1 import compute_SV_gradient_rank2, compute_SV_importance_rank, compute_SV_contribution_rank, compute_SV_decision_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy.stats import pearsonr\n",
    "from mistic_v1 import rank_items\n",
    "\n",
    "class SV_combined_rank():\n",
    "\n",
    "    def __init__(self,weight=0.5):\n",
    "        self.weight = weight\n",
    "\n",
    "    def compute(self,svc,X,y):\n",
    "        contribution_rank = compute_SV_contribution_rank(svc,X,y)\n",
    "        importance_rank = compute_SV_importance_rank(svc,X,y)\n",
    "\n",
    "        consensus_rank = self.weight*contribution_rank + (1-self.weight)*importance_rank\n",
    "        rank = rank_items(consensus_rank)\n",
    "        \n",
    "        return rank\n",
    "\n",
    "class svc_score():\n",
    "\n",
    "    def __init__(self, weight=0.5):\n",
    "        self.weight = weight\n",
    "\n",
    "    def score(self,svc,X,y):\n",
    "        y_pred = svc.predict(X)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "        if (tp+fp) > 0:\n",
    "            precision = tp/(tp+fp)\n",
    "        else:\n",
    "            precision = 0\n",
    "            \n",
    "        if (tp+fn) > 0:\n",
    "            recall = tp/(tp+fn)\n",
    "        else:\n",
    "            recall = 0\n",
    "        \n",
    "        if (precision+recall) > 0:\n",
    "            f1 = 2*precision*recall/(precision+recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "            \n",
    "        auc = roc_auc_score(y, svc.decision_function(X))\n",
    "        score = self.weight*auc + (1-self.weight)*f1\n",
    "            \n",
    "        return pd.DataFrame(data={'f1': f1, 'auc': auc, 'score': score},index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from mistic_v1 import compute_SV_integrated_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from seaborn import pairplot, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some functions I wrote to help with exporting data\n",
    "def outputToExcel(df_data, fileName_header, fileName_Common, fileName_suffix,\n",
    "                  parent_dir, folderName, sheetName):\n",
    "    fileName = fileName_header + fileName_Common + fileName_suffix\n",
    "    outfile_extension = '.xlsx'\n",
    "    outfile_boxplts = fileName + outfile_extension\n",
    "    path_out= os.path.join(parent_dir, folderName, outfile_boxplts)\n",
    "\n",
    "    if os.path.exists(path_out):\n",
    "            #if old sheet\n",
    "            with pd.ExcelWriter(path_out, mode = 'a', if_sheet_exists = 'overlay') as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True)\n",
    "    else: \n",
    "            #new sheet\n",
    "            with pd.ExcelWriter(path_out) as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True) #if new sheet\n",
    "    \n",
    "def outputFiguresPath(fileName_header, fileName_mid, fileName_suff, parent_dir, folderName):\n",
    "        fileName_header = str(fileName_header)\n",
    "        fileName_mid = str(fileName_mid)\n",
    "        fileName_suff = str(fileName_suff)\n",
    "\n",
    "        #cleaning the input to prevent addition of / to the directory\n",
    "        fileName_header = fileName_header.replace(\"/\", \"-\")\n",
    "        fileName_mid = fileName_mid.replace(\"/\", \"-\")\n",
    "        fileName_suff = fileName_suff.replace(\"/\", \"-\")\n",
    "\n",
    "        fileName = fileName_header + fileName_mid +fileName_suff\n",
    "        out_filename = fileName + '.tif'\n",
    "        new_filepath = os.path.join(parent_dir, folderName, out_filename)\n",
    "        #the output path can be used to save the figure\n",
    "        return new_filepath\n",
    "        # plt.savefig(new_filepath, bbox_inches = 'tight')\n",
    "\n",
    "def makeFolderPathForData(parent_dir, folderName_header, folderName_common, folderName_suffix):\n",
    "    #makes a new directory for your files\n",
    "    #returns the folder name for use in other functions\n",
    "    folderName = folderName_header + folderName_common + folderName_suffix\n",
    "    path = os.path.join(parent_dir,folderName)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return folderName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#consider changing dirrectory back to a space to save your data that isn't the mistic folder\n",
    "\n",
    "# new_dirrectory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/SVM_Mistic_Output_2024-07-12_v2\"\n",
    "# os.chdir(new_dirrectory)\n",
    "\n",
    "#for file outputs\n",
    "fileName_header = \"top60E_all_240806_Red01_CVrankTrain_\" #what data did you put in\n",
    "fileName_common = \"Mistic_\" #what was performed on the data, for figures, this may be added to\n",
    "fileName_suffix = \"_2024-08-27_v1\" #date and versioning\n",
    "\n",
    "# saving_dirrectory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/\"\n",
    "saving_dirrectory = \"012 Processed Data\"\n",
    "makingFolder = makeFolderPathForData(parent_dir= saving_dirrectory, folderName_header= \"SVM_Mistic_top60E_all_240806_Red01_CVrankTrain_\", folderName_common= \"2024-08-27_\", \n",
    "                                     folderName_suffix= \"v1\")\n",
    "dataFrameFolderOut =  makingFolder #\"SVM_Mistic_Output_2024-07-19_v2\"\n",
    "pickleFolderOut = makingFolder\n",
    "\n",
    "figDirectory = \"012 Processed Data\"\n",
    "figFolder = makingFolder #\"SVM_Mistic_Output_2024-07-19_v2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#file name for inputs\n",
    "#file full with directory\n",
    "# fileInput_directory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/DFsForSVM_top60labs_2024-07-26_v1/AL-KnownPts-top60Labs-wFill-Fits-One_2024-07-26_v1.xlsx\"\n",
    "# \"C:\\Users\\maega\\Documents\\3000 PhD\\3300_BEAT Labs\\Projects\\Cardiac-Amyloidosis-Multiple-Myeloma\\012 Processed Data\\DFsForSVM_top60labs_2024-07-26_v1\"\n",
    "fileInput_directory = 'AL-KnownPts_top60E_1Sheet_2024-08-06_v1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeID</th>\n",
       "      <th>Amyloid Status</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Survival (in months)</th>\n",
       "      <th>time from diagnosis to first echo (months)</th>\n",
       "      <th>1st_EF(avg%)</th>\n",
       "      <th>1st_Diastolic grade</th>\n",
       "      <th>1st_BSA</th>\n",
       "      <th>...</th>\n",
       "      <th>ChemoTx</th>\n",
       "      <th>ChemoTx Number</th>\n",
       "      <th>ImmunoTx</th>\n",
       "      <th>ImmunoTx Number</th>\n",
       "      <th>HemeTx</th>\n",
       "      <th>HemeTx Number</th>\n",
       "      <th>RadTx</th>\n",
       "      <th>RadTx Number</th>\n",
       "      <th>OtherTx</th>\n",
       "      <th>OtherTx Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>67.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>62.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.73</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>71.300000</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>20.466667</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G-01</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>102.166667</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-01</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>62.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>57.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.56</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>93.900000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>62.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.04</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>L-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>57.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>9.966667</td>\n",
       "      <td>27.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>N-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>O-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>4.233333</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>52.5</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>41.100000</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>47.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q-03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>3.466667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>57.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>14.433333</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>57.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>62.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.59</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>W-01</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>52.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>X-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>-3.933333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>X-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>38.233333</td>\n",
       "      <td>23.033333</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Y-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>77.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>7.266667</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>B-03</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>62.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.91</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>E-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>13.866667</td>\n",
       "      <td>4.433333</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>F-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>142.266667</td>\n",
       "      <td>62.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.19</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>G-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>11.533333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>H-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>47.066667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>57.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>H-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.366667</td>\n",
       "      <td>57.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>J-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>59.200000</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>M-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>12.866667</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>N-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>N-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>57.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>P-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>39.833333</td>\n",
       "      <td>37.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>P-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Q-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>R-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>52.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.68</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>R-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>12.966667</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>S-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>T-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>6.866667</td>\n",
       "      <td>52.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>V-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>5.766667</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>W-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Y-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>62.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.59</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Z-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>57.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows Ã— 3654 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DeID  Amyloid Status  Dx  Sex  Age  Survival (in months)  \\\n",
       "0   B-02               2   1    0   48              9.466667   \n",
       "1   C-03               2   2    1   59             17.000000   \n",
       "2   E-01               2   1    0   50             71.300000   \n",
       "3   E-02               2   1    0   64             20.466667   \n",
       "4   F-03               2   2    0   61             52.000000   \n",
       "5   G-01               2   2    0   70            104.000000   \n",
       "6   G-02               2   2    1   36             30.000000   \n",
       "7   I-01               2   2    1   55             33.000000   \n",
       "8   I-03               2   1    0   67             10.033333   \n",
       "9   J-02               2   2    1   68             26.000000   \n",
       "10  K-01               2   1    1   70             93.900000   \n",
       "11  K-02               2   2    1   68             27.000000   \n",
       "12  L-02               2   2    0   56              6.000000   \n",
       "13  M-02               2   1    0   70             24.800000   \n",
       "14  N-03               2   2    0   69              8.000000   \n",
       "15  O-03               2   2    1   71              4.233333   \n",
       "16  Q-02               2   1    0   69             41.100000   \n",
       "17  Q-03               2   2    1   41              3.466667   \n",
       "18  T-01               2   0    0   71             14.433333   \n",
       "19  V-02               2   2    0   79             50.000000   \n",
       "20  W-01               2   2    0   57             42.000000   \n",
       "21  X-01               2   1    0   80              5.300000   \n",
       "22  X-02               2   1    0   63             38.233333   \n",
       "23  Y-02               2   1    1   57             12.766667   \n",
       "24  A-02               1   1    1   74              7.266667   \n",
       "25  B-03               1   2    0   43             18.000000   \n",
       "26  C-01               1   0    1   56             27.000000   \n",
       "27  C-02               1   2    0   59             33.000000   \n",
       "28  E-03               1   1    0   62             13.866667   \n",
       "29  F-01               1   2    0   55            147.000000   \n",
       "30  G-03               1   1    1   69             11.533333   \n",
       "31  H-01               1   1    0   56             47.066667   \n",
       "32  H-02               1   2    0   65             26.000000   \n",
       "33  J-01               1   2    0   60             94.000000   \n",
       "34  M-01               1   2    0   47             83.000000   \n",
       "35  N-01               1   0    0   79             15.000000   \n",
       "36  N-02               1   2    0   76             10.000000   \n",
       "37  P-01               1   2    0   77             53.000000   \n",
       "38  P-02               1   2    1   64             26.000000   \n",
       "39  Q-01               1   1    1   57             48.800000   \n",
       "40  R-01               1   2    0   68             21.000000   \n",
       "41  R-03               1   1    1   62             12.966667   \n",
       "42  S-02               1   2    1   69             20.000000   \n",
       "43  T-02               1   2    0   60             19.000000   \n",
       "44  V-01               1   2    1   66             43.000000   \n",
       "45  W-02               1   1    0   72             13.500000   \n",
       "46  Y-01               1   2    0   59             40.000000   \n",
       "47  Z-01               1   0    1   72              2.000000   \n",
       "\n",
       "    time from diagnosis to first echo (months)  1st_EF(avg%)  \\\n",
       "0                                     4.433333          67.5   \n",
       "1                                    -0.033333          62.5   \n",
       "2                                    21.666667          62.0   \n",
       "3                                     2.100000          60.0   \n",
       "4                                    -1.000000          -1.0   \n",
       "5                                   102.166667          55.0   \n",
       "6                                     4.400000          50.0   \n",
       "7                                     1.133333          62.5   \n",
       "8                                     1.633333          57.5   \n",
       "9                                     0.900000          47.5   \n",
       "10                                   86.000000          42.0   \n",
       "11                                    0.566667          62.5   \n",
       "12                                    3.866667          57.5   \n",
       "13                                    9.966667          27.5   \n",
       "14                                    4.466667          47.5   \n",
       "15                                   -0.066667          52.5   \n",
       "16                                   34.766667          47.5   \n",
       "17                                    0.700000          57.5   \n",
       "18                                    2.933333          57.5   \n",
       "19                                   49.800000          62.5   \n",
       "20                                    1.666667          52.5   \n",
       "21                                   -3.933333          60.0   \n",
       "22                                   23.033333          57.5   \n",
       "23                                    0.566667          77.5   \n",
       "24                                    6.333333          64.0   \n",
       "25                                    2.333333          62.5   \n",
       "26                                    1.666667          62.5   \n",
       "27                                    3.233333          62.5   \n",
       "28                                    4.433333          62.5   \n",
       "29                                  142.266667          62.5   \n",
       "30                                    0.900000          52.5   \n",
       "31                                    4.500000          57.5   \n",
       "32                                    7.366667          57.5   \n",
       "33                                   59.200000          67.5   \n",
       "34                                   12.866667          67.5   \n",
       "35                                   -0.266667          62.5   \n",
       "36                                    1.900000          57.5   \n",
       "37                                   39.833333          37.5   \n",
       "38                                    9.100000          62.5   \n",
       "39                                   11.500000          67.5   \n",
       "40                                    4.700000          52.5   \n",
       "41                                    5.300000          62.5   \n",
       "42                                    6.300000          58.0   \n",
       "43                                    6.866667          52.5   \n",
       "44                                    5.766667          62.5   \n",
       "45                                    6.533333          62.5   \n",
       "46                                    0.200000          62.5   \n",
       "47                                   -0.700000          57.5   \n",
       "\n",
       "    1st_Diastolic grade  1st_BSA  ...  ChemoTx  ChemoTx Number  ImmunoTx  \\\n",
       "0                     1     1.80  ...        0               0         0   \n",
       "1                     2     1.73  ...        1               2         0   \n",
       "2                     0     2.17  ...        0               0         0   \n",
       "3                     1    -1.00  ...        0               0         0   \n",
       "4                    -1    -1.00  ...        1               4         0   \n",
       "5                     2    -1.00  ...        0               0         1   \n",
       "6                     3     2.12  ...        0               0         0   \n",
       "7                     1     1.99  ...        1               4         1   \n",
       "8                     1     1.99  ...        0               0         0   \n",
       "9                    -1     1.56  ...        1               1         1   \n",
       "10                    1    -1.00  ...        0               0         0   \n",
       "11                    2     2.04  ...        1               1         0   \n",
       "12                    1    -1.00  ...        0               0         0   \n",
       "13                    3     1.96  ...        0               0         0   \n",
       "14                   -1     2.41  ...        0               0         0   \n",
       "15                    3    -1.00  ...        0               0         0   \n",
       "16                   -1     2.10  ...        0               0         0   \n",
       "17                    3     2.31  ...        0               0         0   \n",
       "18                    3     2.43  ...        0               0         0   \n",
       "19                    1     1.59  ...        1               1         0   \n",
       "20                    1     1.72  ...        1               3         1   \n",
       "21                   -1    -1.00  ...        0               0         0   \n",
       "22                    0     2.11  ...        0               0         0   \n",
       "23                    1    -1.00  ...        0               0         0   \n",
       "24                    1    -1.00  ...        0               0         0   \n",
       "25                    2     1.91  ...        1               3         1   \n",
       "26                    0     1.99  ...        0               0         0   \n",
       "27                    0     2.03  ...        1               2         1   \n",
       "28                    0     1.93  ...        0               0         0   \n",
       "29                    1     2.19  ...        1               5         1   \n",
       "30                    0     1.49  ...        0               0         0   \n",
       "31                    2     1.99  ...        0               0         0   \n",
       "32                    1     2.17  ...        1               2         1   \n",
       "33                    0     2.08  ...        0               0         0   \n",
       "34                    0     2.00  ...        1               1         1   \n",
       "35                    0     2.00  ...        0               0         0   \n",
       "36                   -1     1.83  ...        1               1         0   \n",
       "37                    2     2.01  ...        1               1         1   \n",
       "38                    0     2.06  ...        1               4         0   \n",
       "39                    0     1.60  ...        0               0         0   \n",
       "40                    1     1.68  ...        1               3         0   \n",
       "41                    0     2.19  ...        0               0         0   \n",
       "42                    0    -1.00  ...        1               2         0   \n",
       "43                    2     2.13  ...        1               3         0   \n",
       "44                    0     2.16  ...        1               2         1   \n",
       "45                    0    -1.00  ...        0               0         0   \n",
       "46                    1     2.59  ...        1               5         1   \n",
       "47                    1     1.96  ...        0               0         0   \n",
       "\n",
       "    ImmunoTx Number  HemeTx  HemeTx Number  RadTx  RadTx Number  OtherTx  \\\n",
       "0                 0       0              0      0             0        0   \n",
       "1                 0       0              0      0             0        0   \n",
       "2                 0       0              0      0             0        0   \n",
       "3                 0       0              0      0             0        0   \n",
       "4                 0       1              1      0             0        0   \n",
       "5                 1       0              0      0             0        0   \n",
       "6                 0       0              0      0             0        0   \n",
       "7                 2       0              0      0             0        0   \n",
       "8                 0       0              0      0             0        0   \n",
       "9                 1       0              0      0             0        0   \n",
       "10                0       0              0      0             0        0   \n",
       "11                0       0              0      0             0        0   \n",
       "12                0       0              0      0             0        0   \n",
       "13                0       0              0      0             0        0   \n",
       "14                0       0              0      0             0        0   \n",
       "15                0       0              0      0             0        0   \n",
       "16                0       0              0      0             0        0   \n",
       "17                0       0              0      0             0        0   \n",
       "18                0       0              0      0             0        0   \n",
       "19                0       0              0      0             0        0   \n",
       "20                3       0              0      0             0        0   \n",
       "21                0       0              0      0             0        0   \n",
       "22                0       0              0      0             0        0   \n",
       "23                0       0              0      0             0        0   \n",
       "24                0       0              0      0             0        0   \n",
       "25                2       0              0      0             0        0   \n",
       "26                0       0              0      0             0        0   \n",
       "27                2       1              1      0             0        0   \n",
       "28                0       0              0      0             0        0   \n",
       "29                1       1              1      0             0        0   \n",
       "30                0       0              0      0             0        0   \n",
       "31                0       0              0      0             0        0   \n",
       "32                1       1              1      1             1        0   \n",
       "33                0       0              0      0             0        1   \n",
       "34                1       0              0      0             0        0   \n",
       "35                0       0              0      0             0        1   \n",
       "36                0       0              0      0             0        0   \n",
       "37                1       0              0      0             0        0   \n",
       "38                0       1              1      0             0        0   \n",
       "39                0       0              0      0             0        0   \n",
       "40                0       1              1      0             0        0   \n",
       "41                0       0              0      0             0        0   \n",
       "42                0       0              0      0             0        0   \n",
       "43                0       1              1      0             0        0   \n",
       "44                1       1              1      0             0        0   \n",
       "45                0       0              0      0             0        0   \n",
       "46                1       0              0      0             0        0   \n",
       "47                0       0              0      0             0        0   \n",
       "\n",
       "    OtherTx Number  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "5                0  \n",
       "6                0  \n",
       "7                0  \n",
       "8                0  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               0  \n",
       "16               0  \n",
       "17               0  \n",
       "18               0  \n",
       "19               0  \n",
       "20               0  \n",
       "21               0  \n",
       "22               0  \n",
       "23               0  \n",
       "24               0  \n",
       "25               0  \n",
       "26               0  \n",
       "27               0  \n",
       "28               0  \n",
       "29               0  \n",
       "30               0  \n",
       "31               0  \n",
       "32               0  \n",
       "33               2  \n",
       "34               0  \n",
       "35               2  \n",
       "36               0  \n",
       "37               0  \n",
       "38               0  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               0  \n",
       "44               0  \n",
       "45               0  \n",
       "46               0  \n",
       "47               0  \n",
       "\n",
       "[48 rows x 3654 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Import dataset\n",
    "\n",
    "dataTable = pd.read_excel(fileInput_directory, header = 0)\n",
    "dataTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#columns to drop from the x data (samples and features)\n",
    "x_columns_toDrop = ['DeID', 'Amyloid Status']\n",
    "\n",
    "\n",
    "#columns to use for the y data \n",
    "y_column_Classification = 'Amyloid Status'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.74270874, -0.77459667, -1.52139307, ..., -0.14586499,\n",
       "        -0.20851441, -0.20851441],\n",
       "       [ 0.8072921 ,  1.29099445, -0.40879537, ..., -0.14586499,\n",
       "        -0.20851441, -0.20851441],\n",
       "       [-0.74270874, -0.77459667, -1.31910258, ..., -0.14586499,\n",
       "        -0.20851441, -0.20851441],\n",
       "       ...,\n",
       "       [-0.74270874, -0.77459667,  0.90609283, ..., -0.14586499,\n",
       "        -0.20851441, -0.20851441],\n",
       "       [ 0.8072921 , -0.77459667, -0.40879537, ..., -0.14586499,\n",
       "        -0.20851441, -0.20851441],\n",
       "       [-2.29270958,  1.29099445,  0.90609283, ..., -0.14586499,\n",
       "        -0.20851441, -0.20851441]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale input X\n",
    "X = dataTable.copy()\n",
    "X.drop(columns= x_columns_toDrop,inplace=True)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X) #computes the mean and STD along the features axis\n",
    "\n",
    "X_train_all = scaler.transform(X) #standardization by centering and scaling\n",
    "y_train_all = dataTable[y_column_Classification]\n",
    "X_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the test and train sets \n",
    "pickle_file_name = 'X_train_all_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(X_train_all, pickle_file)\n",
    "\n",
    "pickle_file_name = 'y_train_all_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(y_train_all, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the scalar so that new data can be applied and mapped to use this classifier\n",
    "pickle_file_name = 'scaler_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(scaler, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading from pickled objects\n",
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'X_train_all_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# X_train_all = pickle.load(pickle_file)\n",
    "\n",
    "# #uploading the y train object\n",
    "# pickle_file_name = 'y_train_all_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# y_train_all = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of training sets\n",
    "NT = 5 \n",
    "\n",
    "# Data split ratio\n",
    "val_size = 1/NT\n",
    "\n",
    "#Feature selection reduction factor\n",
    "red_factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split train set into train and test(val) data / repeat NT times and |get NT number of datsets\n",
    "CV_sets = []\n",
    "for i in range(NT):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_all, y_train_all, \n",
    "                                                        stratify = y_train_all, \n",
    "                                                        random_state= i, \n",
    "                                                        test_size= val_size)\n",
    "    \n",
    "    CV_set = {\"train\": {\"X\": X_train,\"y\": y_train}, \"test\":  {\"X\": X_test, \"y\": y_test}} \n",
    "    CV_sets.append(CV_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the CV sets object\n",
    "pickle_file_name = 'CV_sets_object_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(CV_sets, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'CV_sets_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# CV_sets = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "C_range = [2**x for x in range(-2,5)] # trade-off between margin and misclassifications.  smaller c, wider margins\n",
    "gamma_range = [2**x for x in range(-9,1)]\n",
    "\n",
    "svc = SVC(kernel = 'rbf', class_weight=\"balanced\", probability=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tesTune, the first classifier using all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>g</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.544286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      c  g        f1   auc     score\n",
       "0  0.25  1  0.628571  0.46  0.544286"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesTune = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range)\n",
    "tesTune[\"best_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving the first test tune set\n",
    "perf = tesTune[\"performance\"]\n",
    "tesTune_best_params = tesTune[\"best_params\"]\n",
    "\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"tesTune perf\")\n",
    "outputToExcel(df_data=tesTune_best_params, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"tesTune best params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the tesTune object\n",
    "pickle_file_name = 'tesTune_object_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(tesTune, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'tesTune_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# tesTune = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesTune[\"best_models\"][0].classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## greedy_backward_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### featRank_A fresh compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.628571  0.46  0.544286    3652      19.0\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.628571  0.46  0.544286    3286      19.0\n",
      "   c     g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.25  0.416667  0.472  0.444333    2957      19.0\n",
      "   c    g        f1  auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.475556  0.4  0.437778    2661      19.0\n",
      "   c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.125  0.545238  0.372  0.458619    2394      19.0\n",
      "   c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.125  0.545238  0.364  0.454619    2154      19.0\n",
      "   c      g       f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.125  0.47619  0.268  0.372095    1938      19.0\n",
      "   c    g        f1    auc    score  nFeats  mean_nSV\n",
      "0  2  0.5  0.347619  0.436  0.39181    1744      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.304762  0.436  0.370381    1569      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.339927  0.424  0.381963    1412      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.314286  0.416  0.365143    1270      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.450346  0.332  0.391173    1142      19.0\n",
      "      c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.391818  0.324  0.357909    1027      19.0\n",
      "   c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  1  0.5  0.419048  0.42  0.419524     924      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.5  0.392857  0.436  0.414429     831      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  1  0.375714  0.404  0.389857     747      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  1  0.459048  0.404  0.431524     672      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  1  0.564982  0.424  0.494491     604      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.618315  0.416  0.517158     543      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.638828  0.496  0.567414     488      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.596337  0.472  0.534168     439      19.0\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.596337  0.48  0.538168     395      19.0\n",
      "      c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.676923  0.464  0.570462     355      19.0\n",
      "      c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.449018  0.456  0.452509     319      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.003906  0.470476  0.456  0.463238     287      19.0\n",
      "   c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  4  0.001953  0.67619  0.448  0.562095     258      19.0\n",
      "      c       g       f1    auc    score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.72674  0.744  0.73537     232      19.0\n",
      "     c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.5  0.5  0.553846  0.608  0.580923     208      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  8  0.001953  0.542857  0.512  0.527429     187      19.0\n",
      "      c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.616  0.646095     168      19.0\n",
      "      c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.656  0.666095     151      19.0\n",
      "      c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.656  0.666095     135      19.0\n",
      "      c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.656  0.666095     121      19.0\n",
      "      c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.67619  0.648  0.662095     108      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.015625  0.695238  0.644  0.669619      97      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.015625  0.695238  0.644  0.669619      87      19.0\n",
      "     c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.5  0.5  0.710256  0.644  0.677128      78      19.0\n",
      "      c        g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.03125  0.685714  0.58  0.632857      70      19.0\n",
      "      c        g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.03125  0.685714  0.58  0.632857      62      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.54  0.603333      55      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.54  0.603333      49      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.54  0.603333      44      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.54  0.603333      39      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.54  0.603333      35      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.54  0.603333      31      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.54  0.603333      27      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.52  0.598095      24      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.52  0.598095      21      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.015625  0.67619  0.52  0.598095      18      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.52  0.598095      16      19.0\n",
      "      c        g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.03125  0.67619  0.52  0.598095      14      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.52  0.598095      12      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.52  0.598095      10      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.67619  0.52  0.598095       8      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.67619  0.52  0.598095       7      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.67619  0.52  0.598095       6      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.67619  0.52  0.598095       5      19.0\n",
      "      c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.67619  0.52  0.598095       4      19.0\n",
      "      c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.5  0.583333       3      19.0\n",
      "      c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.5  0.583333       2      19.0\n",
      "      c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.666667  0.5  0.583333       1      19.0\n"
     ]
    }
   ],
   "source": [
    "featRank_A = greedy_backward_selection(svc, X_train_all, CV_sets, compute_SV_importance_rank, svc_score().score, C_range, gamma_range, redF = red_factor, \n",
    "                                       filter_correlated = False, CV_set_for_rank = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if not already pickled use this block\n",
    "pickle_file_name = 'featRankA_object_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_A, pickle_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_A[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_A[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_A[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_A[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_A[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A feature rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featRank_A upload from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankA_object_' + fileName_header +fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_A = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile featRank_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.628571  0.46  0.544286    3652      19.0\n",
      "      c  g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.568498  0.4  0.484249    3286      19.0\n",
      "      c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.568498  0.364  0.466249    2957      19.0\n",
      "      c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.515152  0.384  0.449576    2661      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.455758  0.472  0.463879    2394      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.455758  0.472  0.463879    2154      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.455758  0.472  0.463879    1938      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.455758  0.472  0.463879    1744      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.455758  0.464  0.459879    1569      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.457143  0.44  0.448571    1412      19.0\n",
      "   c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.41873  0.448  0.433365    1270      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.435758  0.448  0.441879    1142      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.472222  0.488  0.480111    1027      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.494012  0.512  0.503006     924      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.483333  0.528  0.505667     831      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.520635  0.536  0.528317     747      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.458889  0.648  0.553444     672      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.533333  0.672  0.602667     604      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.655556  0.744  0.699778     543      19.0\n",
      "   c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.65641  0.784  0.720205     488      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.001953  0.693333  0.848  0.770667     439      19.0\n",
      "   c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  1  0.001953  0.804444  0.88  0.842222     395      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  0.001953  0.787778  0.896  0.841889     355      18.8\n",
      "   c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  1  0.001953  0.784343  0.92  0.852172     319      18.6\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.001953  0.812121  0.944  0.878061     287      18.4\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.001953  0.834343  0.944  0.889172     258      18.2\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  0.003906  0.865556  0.952  0.908778     232      18.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  0.001953  0.852063  0.936  0.894032     208      17.2\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.905556  0.944  0.924778     187      16.8\n",
      "     c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.5  0.003906  0.905556  0.928  0.916778     168      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  0.003906  0.905556  0.952  0.928778     151      18.0\n",
      "   c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.905556  0.96  0.932778     135      17.0\n",
      "   c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  8  0.001953  0.933333  0.96  0.946667     121      15.0\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.933333  1.0  0.966667     108      16.2\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  8  0.003906  0.955556  0.984  0.969778      97      15.6\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  8  0.003906  0.955556  0.984  0.969778      87      15.8\n",
      "    c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  16  0.003906  0.955556  0.992  0.973778      78      15.0\n",
      "    c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  16  0.001953  0.955556  0.992  0.973778      70      14.2\n",
      "    c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  16  0.001953  0.955556  1.0  0.977778      62      13.6\n",
      "    c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  16  0.001953  0.927778  1.0  0.963889      55      13.6\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  1  0.003906  0.905556  1.0  0.952778      49      18.4\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  0.003906  0.933333  0.992  0.962667      44      13.4\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  1  0.007812  0.977778  1.0  0.988889      39      17.0\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  2  0.003906  0.977778  1.0  0.988889      35      16.0\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  2  0.007812  0.981818  1.0  0.990909      31      14.2\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  4  0.001953  0.977778  1.0  0.988889      27      16.4\n",
      "    c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  16  0.001953  0.981818  0.992  0.986909      24       9.2\n",
      "      c       g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.981818  1.0  0.990909      21      19.0\n",
      "     c         g   f1  auc  score  nFeats  mean_nSV\n",
      "0  0.5  0.015625  1.0  1.0    1.0      18      17.6\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  2  0.007812  0.981818  1.0  0.990909      16      14.2\n",
      "   c         g        f1  auc     score  nFeats  mean_nSV\n",
      "0  1  0.015625  0.955556  1.0  0.977778      14      16.2\n",
      "   c         g   f1  auc  score  nFeats  mean_nSV\n",
      "0  2  0.015625  1.0  1.0    1.0      12      12.0\n",
      "     c       g   f1  auc  score  nFeats  mean_nSV\n",
      "0  0.5  0.0625  1.0  1.0    1.0      10      16.8\n",
      "      c       g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.955556  1.0  0.977778       8      19.0\n",
      "   c       g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.0625  0.977778  0.992  0.984889       7      13.8\n",
      "     c        g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.5  0.03125  0.905556  0.968  0.936778       6      17.8\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  8  0.007812  0.927778  0.952  0.939889       5      11.4\n",
      "   c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.125  0.873882  0.936  0.904941       4       8.8\n",
      "     c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.5  0.125  0.777778  0.904  0.840889       3      16.0\n",
      "   c     g        f1    auc    score  nFeats  mean_nSV\n",
      "0  1  0.25  0.753939  0.776  0.76497       2      15.0\n",
      "     c     g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.5  0.25  0.706667  0.748  0.727333       1      16.4\n"
     ]
    }
   ],
   "source": [
    "featRank_B = greedy_backward_selection(svc, X_train_all, CV_sets, compute_SV_contribution_rank, svc_score().score, C_range, gamma_range, redF = red_factor,\n",
    "                                       filter_correlated = False, CV_set_for_rank = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankB_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_B, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_B[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_B[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_B[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_B[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_B[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B feature rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load featRank_B from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankB_object_' + fileName_header +fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_B = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile featRank_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.628571  0.46  0.544286    3652      19.0\n",
      "      c  g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.568498  0.4  0.484249    3286      19.0\n",
      "   c       g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.0625  0.605128  0.372  0.488564    2957      19.0\n",
      "   c       g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.0625  0.595238  0.384  0.489619    2661      19.0\n",
      "   c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.125  0.545238  0.376  0.460619    2394      19.0\n",
      "      c        g       f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.03125  0.52619  0.284  0.405095    2154      19.0\n",
      "      c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.453016  0.348  0.400508    1938      19.0\n",
      "   c     g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.25  0.361905  0.396  0.378952    1744      19.0\n",
      "   c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.285714  0.48  0.382857    1569      19.0\n",
      "      c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.285714  0.444  0.364857    1412      19.0\n",
      "      c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.285714  0.444  0.364857    1270      19.0\n",
      "      c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.285714  0.444  0.364857    1142      19.0\n",
      "    c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  16  0.001953  0.315325  0.408  0.361662    1027      18.0\n",
      "   c         g       f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.003906  0.20873  0.304  0.256365     924      19.0\n",
      "      c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.404895  0.452  0.428448     831      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  1  0.397172  0.364  0.380586     747      15.8\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  0.5  0.327042  0.408  0.367521     672      15.8\n",
      "    c        g        f1   auc     score  nFeats  mean_nSV\n",
      "0  16  0.03125  0.263203  0.44  0.351602     604      16.8\n",
      "      c     g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.25  0.276032  0.408  0.342016     543      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.003906  0.240476  0.512  0.376238     488      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.224444  0.372  0.298222     439      17.8\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.196032  0.416  0.306016     395      18.6\n",
      "   c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  8  1  0.146032  0.44  0.293016     355      18.6\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  4  1  0.146032  0.424  0.285016     319      18.6\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.146032  0.484  0.315016     287      18.8\n",
      "   c     g       f1    auc     score  nFeats  mean_nSV\n",
      "0  8  0.25  0.30641  0.464  0.385205     258      19.0\n",
      "   c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  4  0.5  0.287363  0.46  0.373681     232      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.328788  0.484  0.406394     208      19.0\n",
      "      c         g   f1    auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.4  0.424  0.412     187      19.0\n",
      "      c         g   f1    auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.4  0.368  0.384     168      19.0\n",
      "   c         g   f1    auc  score  nFeats  mean_nSV\n",
      "0  2  0.001953  0.4  0.464  0.432     151      19.0\n",
      "      c         g   f1    auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.4  0.432  0.416     135      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.015625  0.380952  0.664  0.522476     121      19.0\n",
      "      c     g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.25  0.523077  0.676  0.599538     108      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.523077  0.676  0.599538      97      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.523077  0.676  0.599538      87      19.0\n",
      "      c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.125  0.523077  0.732  0.627538      78      19.0\n",
      "      c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.125  0.514286  0.772  0.643143      70      19.0\n",
      "      c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.125  0.514286  0.772  0.643143      62      19.0\n",
      "      c      g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.125  0.514286  0.772  0.643143      55      19.0\n",
      "   c     g        f1   auc     score  nFeats  mean_nSV\n",
      "0  2  0.25  0.514286  0.76  0.637143      49      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.464286  0.768  0.616143      44      18.8\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.464286  0.768  0.616143      39      18.8\n",
      "   c    g   f1    auc  score  nFeats  mean_nSV\n",
      "0  2  0.5  0.3  0.832  0.566      35      18.8\n",
      "      c      g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.125  0.266667  0.46  0.363333      31      19.0\n",
      "   c      g        f1   auc     score  nFeats  mean_nSV\n",
      "0  4  0.125  0.266667  0.46  0.363333      27      18.8\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.266667  0.52  0.393333      24      19.0\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.266667  0.52  0.393333      21      19.0\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.266667  0.52  0.393333      18      19.0\n",
      "      c      g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.125  0.533333  0.48  0.506667      16      19.0\n",
      "      c     g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.25  0.533333  0.48  0.506667      14      19.0\n",
      "      c     g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.25  0.533333  0.48  0.506667      12      19.0\n",
      "      c     g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.25  0.533333  0.48  0.506667      10      19.0\n",
      "      c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.533333  0.48  0.506667       8      19.0\n",
      "      c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.5  0.533333  0.48  0.506667       7      19.0\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.533333  0.48  0.506667       6      19.0\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.533333  0.48  0.506667       5      19.0\n",
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.533333  0.48  0.506667       4      19.0\n",
      "      c         g   f1  auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.0  0.5   0.25       3      19.0\n",
      "      c         g   f1  auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.0  0.5   0.25       2      19.0\n",
      "      c         g   f1  auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.0  0.5   0.25       1      19.0\n"
     ]
    }
   ],
   "source": [
    "featRank_C = greedy_backward_selection(svc, X_train_all, CV_sets, SV_combined_rank(weight=0.25).compute, svc_score().score, C_range, gamma_range, redF = red_factor,\n",
    "                                       filter_correlated = False, CV_set_for_rank = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankC_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_C, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_C[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_C[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_C[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_C[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_C[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C feature rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upload featRank_C from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankC_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_C = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile featRank_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.628571  0.46  0.544286    3652      19.0\n",
      "      c  g        f1  auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.568498  0.4  0.484249    3286      19.0\n",
      "      c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.564103  0.376  0.470051    2957      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.455758  0.464  0.459879    2661      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.436667  0.436  0.436333    2394      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.500202  0.376  0.438101    2154      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.451282  0.448  0.449641    1938      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  1  0.425641  0.408  0.416821    1744      19.0\n",
      "   c     g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.25  0.495238  0.328  0.411619    1569      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.5  0.517662  0.388  0.452831    1412      19.0\n",
      "   c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.514286  0.34  0.427143    1270      19.0\n",
      "   c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.558974  0.34  0.449487    1142      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.628571  0.336  0.482286    1027      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.558974  0.288  0.423487     924      19.0\n",
      "      c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.322727  0.276  0.299364     831      19.0\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.5  0.406593  0.304  0.355297     747      19.0\n",
      "   c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  1  0.266667  0.468  0.367333     672      19.0\n",
      "      c  g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.266667  0.412  0.339333     604      19.0\n",
      "   c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  1  1  0.266667  0.38  0.323333     543      19.0\n",
      "   c        g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.03125  0.382698  0.304  0.343349     488      19.0\n",
      "   c        g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.03125  0.382698  0.304  0.343349     439      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.366869  0.448  0.407434     395      19.0\n",
      "   c         g       f1   auc     score  nFeats  mean_nSV\n",
      "0  1  0.001953  0.40381  0.48  0.441905     355      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.492121  0.52  0.506061     319      19.0\n",
      "   c        g        f1    auc     score  nFeats  mean_nSV\n",
      "0  8  0.03125  0.621587  0.696  0.658794     287      17.0\n",
      "   c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  1  0.001953  0.707692  0.64  0.673846     258      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.720513  0.664  0.692256     232      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.754978  0.696  0.725489     208      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.003906  0.754978  0.704  0.729489     187      19.0\n",
      "     c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.5  0.003906  0.742158  0.656  0.699079     168      19.0\n",
      "      c         g      f1    auc    score  nFeats  mean_nSV\n",
      "0  0.25  0.007812  0.7671  0.696  0.73155     151      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.007812  0.754978  0.704  0.729489     135      19.0\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.015625  0.760433  0.728  0.744216     121      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.003906  0.761538  0.736  0.748769     108      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.007812  0.783883  0.736  0.759941      97      18.8\n",
      "   c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  2  0.003906  0.761538  0.76  0.760769      87      18.8\n",
      "   c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  2  0.003906  0.761538  0.76  0.760769      78      18.4\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.003906  0.761538  0.792  0.776769      70      18.6\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.003906  0.761538  0.784  0.772769      62      17.8\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.003906  0.761538  0.816  0.788769      55      18.0\n",
      "      c        g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.03125  0.824675  0.84  0.832338      49      18.6\n",
      "      c        g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.03125  0.824675  0.84  0.832338      44      18.8\n",
      "      c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.015625  0.824675  0.808  0.816338      39      19.0\n",
      "      c       g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.824675  0.84  0.832338      35      18.8\n",
      "      c       g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.802857  0.84  0.821429      31      18.8\n",
      "      c       g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.802857  0.824  0.813429      27      18.8\n",
      "   c        g        f1  auc     score  nFeats  mean_nSV\n",
      "0  1  0.03125  0.824675  0.8  0.812338      24      17.4\n",
      "      c        g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.03125  0.824675  0.792  0.808338      21      19.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.015625  0.761538  0.824  0.792769      18      18.0\n",
      "   c         g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.015625  0.774359  0.808  0.791179      16      17.8\n",
      "   c        g        f1    auc     score  nFeats  mean_nSV\n",
      "0  1  0.03125  0.774359  0.824  0.799179      14      17.8\n",
      "    c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  16  0.5  0.824675  0.904  0.864338      12      15.6\n",
      "    c    g        f1   auc     score  nFeats  mean_nSV\n",
      "0  16  0.5  0.824675  0.84  0.832338      10      15.6\n",
      "   c    g        f1    auc     score  nFeats  mean_nSV\n",
      "0  8  0.5  0.824675  0.808  0.816338       8      15.6\n",
      "    c       g        f1    auc     score  nFeats  mean_nSV\n",
      "0  16  0.0625  0.774359  0.824  0.799179       7      16.0\n",
      "   c        g        f1    auc     score  nFeats  mean_nSV\n",
      "0  2  0.03125  0.774359  0.808  0.791179       6      17.6\n",
      "      c       g        f1    auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.774359  0.816  0.795179       5      19.0\n",
      "      c       g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.0625  0.774359  0.84  0.807179       4      19.0\n",
      "      c         g   f1    auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.4  0.456  0.428       3      19.0\n",
      "      c         g   f1   auc  score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.4  0.52   0.46       2      19.0\n",
      "      c         g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  0.001953  0.696703  0.56  0.628352       1      19.0\n"
     ]
    }
   ],
   "source": [
    "featRank_D = greedy_backward_selection(svc, X_train_all, CV_sets, SV_combined_rank(weight=0.5).compute, svc_score().score, C_range, gamma_range, redF = red_factor,\n",
    "                                       filter_correlated = False, CV_set_for_rank = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankD_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_D, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_D[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_D[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_D[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_D[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_D[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D feature rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankD_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_D = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comple featRank_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c  g        f1   auc     score  nFeats  mean_nSV\n",
      "0  0.25  1  0.628571  0.46  0.544286    3652      19.0\n"
     ]
    }
   ],
   "source": [
    "featRank_E = greedy_backward_selection(svc, X_train_all, CV_sets, SV_combined_rank(weight=0.75).compute, svc_score().score, C_range, gamma_range, redF = red_factor,\n",
    "                                       filter_correlated = False, CV_set_for_rank = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankE_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_E, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_E[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_E[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_E[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_E[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_E[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E feature rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankE_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_E = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 4))\n",
    "plt.plot(featRank_A[\"performance\"].nFeats, featRank_A[\"performance\"].auc) \n",
    "plt.plot(featRank_C[\"performance\"].nFeats, featRank_C[\"performance\"].auc) \n",
    "plt.plot(featRank_D[\"performance\"].nFeats, featRank_D[\"performance\"].auc) \n",
    "plt.plot(featRank_E[\"performance\"].nFeats, featRank_E[\"performance\"].auc)\n",
    "plt.plot(featRank_B[\"performance\"].nFeats, featRank_B[\"performance\"].auc) \n",
    "\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.legend(['0','0.25','0.5','0.75','1'])\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving figure\n",
    "# figDirectory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/\"\n",
    "# figFolder = \"SVM_Mistic_Draft_Output_2024-07-11_v1\"\n",
    "figCommon = fileName_common + \"fig1\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 4))\n",
    "plt.plot(featRank_A[\"performance\"].nFeats, featRank_A[\"performance\"].f1) \n",
    "plt.plot(featRank_C[\"performance\"].nFeats, featRank_C[\"performance\"].f1) \n",
    "plt.plot(featRank_D[\"performance\"].nFeats, featRank_D[\"performance\"].f1) \n",
    "plt.plot(featRank_E[\"performance\"].nFeats, featRank_E[\"performance\"].f1) \n",
    "plt.plot(featRank_B[\"performance\"].nFeats, featRank_B[\"performance\"].f1) \n",
    "\n",
    "plt.ylim(0,1)\n",
    "\n",
    "plt.legend(['0','0.25','0.5','0.75','1'])\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figCommon = fileName_common + \"fig2\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### narrower window performance plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 4))\n",
    "plt.plot(featRank_A[\"performance\"].nFeats, featRank_A[\"performance\"].auc) \n",
    "plt.plot(featRank_C[\"performance\"].nFeats, featRank_C[\"performance\"].auc) \n",
    "plt.plot(featRank_D[\"performance\"].nFeats, featRank_D[\"performance\"].auc) \n",
    "plt.plot(featRank_E[\"performance\"].nFeats, featRank_E[\"performance\"].auc)\n",
    "plt.plot(featRank_B[\"performance\"].nFeats, featRank_B[\"performance\"].auc) \n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,500)\n",
    "\n",
    "plt.legend(['0','0.25','0.5','0.75','1'])\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.title(\"AUC of Models Top 500 Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figCommon = fileName_common + \"fig1_top500\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 4))\n",
    "plt.plot(featRank_A[\"performance\"].nFeats, featRank_A[\"performance\"].f1) \n",
    "plt.plot(featRank_C[\"performance\"].nFeats, featRank_C[\"performance\"].f1) \n",
    "plt.plot(featRank_D[\"performance\"].nFeats, featRank_D[\"performance\"].f1) \n",
    "plt.plot(featRank_E[\"performance\"].nFeats, featRank_E[\"performance\"].f1) \n",
    "plt.plot(featRank_B[\"performance\"].nFeats, featRank_B[\"performance\"].f1) \n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,500)\n",
    "\n",
    "plt.legend(['0','0.25','0.5','0.75','1'])\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Number of features')\n",
    "plt.title(\"F1 Score for Models Top 500 Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figCommon = fileName_common + \"fig2_top500\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input the top 3 features from your data set into the following plot for a 3D visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[featRank_D[\"sorted\"].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listX = list(X.columns[featRank_D[\"sorted\"].astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(dataTable, x=listX[0], y=listX[1], z=listX[2],\n",
    "              color= y_column_Classification)\n",
    "fig.update_traces(marker_size = 4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance outputs\n",
    "set the number of features you want to check the performance with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting number of features for performance test\n",
    "fold = 0\n",
    "number_feat_perf_test = 25 #describes for testing performance \n",
    "numb_features_figures = 5 #number of features to use in plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryText = \"nFeats == \" + str(number_feat_perf_test)\n",
    "# featRank_B[\"performance\"].query(queryText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {np.int64(2) :'red', np.int64(1): 'blue'} #our data is of int64\n",
    "featuresToPlot = list(X.columns[featRank_A[\"sorted\"].astype(int)][0:numb_features_figures])\n",
    "featuresToPlot.extend([y_column_Classification]) #must include the final classification column \n",
    "\n",
    "fig = pairplot(dataTable[featuresToPlot],hue= y_column_Classification, corner=True, palette=palette)\n",
    "# fig.title(\"featRank_A compare features\")\n",
    "\n",
    "figCommon = fileName_common + \"featRankA\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {np.int64(2) :'red', np.int64(1): 'blue'} #our data is of int64\n",
    "featuresToPlot = list(X.columns[featRank_B[\"sorted\"].astype(int)][0:numb_features_figures])\n",
    "featuresToPlot.extend([y_column_Classification]) #must include the final classification column \n",
    "\n",
    "fig = pairplot(dataTable[featuresToPlot],hue= y_column_Classification, corner=True, palette=palette)\n",
    "# fig.title(\"featRank_A 5 features\", loc = 'center')\n",
    "\n",
    "figCommon = fileName_common + \"featRankB_5\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryText = \"nFeats == \" + str(number_feat_perf_test)\n",
    "# featRank_E[\"performance\"].query(queryText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {np.int64(2) :'red', np.int64(1): 'blue'} #our data is of int64\n",
    "featuresToPlot = list(X.columns[featRank_D[\"sorted\"].astype(int)][0:numb_features_figures])\n",
    "featuresToPlot.extend([y_column_Classification]) #must include the final classification column \n",
    "\n",
    "fig = pairplot(dataTable[featuresToPlot],hue= y_column_Classification, corner=True, palette=palette)\n",
    "# fig.title(\"featRank_A 5 features\", loc = 'center')\n",
    "\n",
    "figCommon = fileName_common + \"featRankD_5\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot(dataTable[['Area worst', 'Concave Points worst', 'Texture worst','Diagnosis']],hue=\"Diagnosis\", corner=True, palette={\"M\":\"red\",\"B\":\"blue\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesTune2 = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range,feature_index=featRank_D[\"sorted\"][0:10].astype(int))\n",
    "# tesTune2[\"best_params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to use best features from a feature selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelD_Features = featRank_D[\"best_features\"] #to get the best features which take highest score and highest C\n",
    "modelD_FeaturesInt = featRank_D[\"best_features\"].astype(int) #convert these to ints? to use as column finding for x.columns?\n",
    "modelD_numbFeatures = len(modelD_FeaturesInt) #number of features\n",
    "\n",
    "#list of column names\n",
    "modelD_FeaturesIntList = X.columns[featRank_D[\"best_features\"].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelE_Features = featRank_E[\"best_features\"] #to get the best features which take highest score and highest C\n",
    "modelE_FeaturesInt = featRank_E[\"best_features\"].astype(int) #convert these to ints? to use as column finding for x.columns?\n",
    "modelE_numbFeatures = len(modelE_FeaturesInt) #number of features\n",
    "\n",
    "#list of column names\n",
    "modelE_FeaturesIntList = X.columns[featRank_E[\"best_features\"].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelB_Features = featRank_B[\"best_features\"] #to get the best features which take highest score and highest C\n",
    "modelB_FeaturesInt = featRank_B[\"best_features\"].astype(int) #convert these to ints? to use as column finding for x.columns?\n",
    "modelB_numbFeatures = len(modelB_FeaturesInt) #number of features\n",
    "\n",
    "#list of column names\n",
    "modelB_FeaturesIntList = X.columns[featRank_B[\"best_features\"].astype(int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures for weighting 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creation of tesTune_05\n",
    "tesTune05 = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range,feature_index=modelD_FeaturesInt)\n",
    "print(tesTune05[\"best_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling of tesTune_05\n",
    "pickle_file_name = 'tesTune05_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(tesTune05, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the parameters for the plots below\n",
    "featuresInt = modelD_FeaturesInt\n",
    "numbFeatures = modelD_numbFeatures\n",
    "ListFeatureColNames = modelD_FeaturesIntList\n",
    "\n",
    "#setting the tuned SVM model for the plots below\n",
    "tunedModel = tesTune05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feat_contribution = compute_SV_decision_perturbation(tunedModel[\"best_models\"][fold],CV_sets[fold][\"test\"][\"X\"][:,featuresInt])\n",
    "# FItable = pd.DataFrame(feat_contribution, index=CV_sets[fold][\"test\"][\"y\"],columns=ListFeatureColNames)\n",
    "\n",
    "# FItable.reset_index(drop=True, inplace=True)\n",
    "# fig = clustermap(FItable.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:], \n",
    "#            yticklabels=False,\n",
    "#            cmap=\"vlag\", vmin=-0.4, vmax=0.4,\n",
    "#            #row_linkage=hcRow, col_linkage=hcCol, \n",
    "#            row_cluster=False,col_cluster=False,\n",
    "#            cbar_pos=(1, .2, .03, .4),\n",
    "#            row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets[0][\"test\"][\"y\"].values[np.argsort(CV_sets[fold][\"test\"][\"y\"].values)]])\n",
    "# plt.suptitle(\"Test Patients Contribution when training with \"+  str(numbFeatures)+ \" best features I-C weight 0.5\")\n",
    "\n",
    "# figCommon = fileName_common + \"fig3_w05\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV_sets_trainANDtest_X = np.concatenate((CV_sets[fold][\"train\"][\"X\"][:,featuresInt],CV_sets[fold][\"test\"][\"X\"][:,featuresInt]), axis =0)\n",
    "CV_sets_trainANDtest_y = np.concatenate((CV_sets[fold][\"train\"][\"y\"],CV_sets[fold][\"test\"][\"y\"]), axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_contribution = compute_SV_decision_perturbation(tunedModel[\"best_models\"][fold],CV_sets_trainANDtest_X)\n",
    "# FItable = pd.DataFrame(feat_contribution, index=CV_sets_trainANDtest_y,columns=ListFeatureColNames)\n",
    "\n",
    "# FItable.reset_index(drop=True, inplace=True)\n",
    "# fig = clustermap(FItable.iloc[np.argsort(CV_sets_trainANDtest_y),:], \n",
    "#            yticklabels=False,\n",
    "#            cmap=\"vlag\", vmin=-0.4, vmax=0.4,\n",
    "#            #row_linkage=hcRow, col_linkage=hcCol, \n",
    "#            row_cluster=False,col_cluster=False,\n",
    "#            cbar_pos=(1, .2, .03, .4),\n",
    "#            row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "# plt.suptitle(\"Contribution test-train when training with best \"+  str(numbFeatures)+ \" features I-C weight 0.5\")\n",
    "\n",
    "# figCommon = fileName_common + \"fig3_2_w05\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CV_sets_trainANDtest_X = np.concatenate((CV_sets[fold][\"train\"][\"X\"][:,modelD_FeaturesInt],CV_sets[fold][\"test\"][\"X\"][:,modelD_FeaturesInt]), axis =0)\n",
    "# CV_sets_trainANDtest_y = np.concatenate((CV_sets[fold][\"train\"][\"y\"],CV_sets[fold][\"test\"][\"y\"]), axis = 0)\n",
    "\n",
    "IG = compute_SV_integrated_gradient(tunedModel[\"best_models\"][fold], CV_sets_trainANDtest_X)\n",
    "\n",
    "IGtable = pd.DataFrame(IG,columns=X.columns[modelD_FeaturesInt])\n",
    "\n",
    "fig = clustermap(IGtable, \n",
    "           yticklabels=False,\n",
    "           cmap=\"vlag\", vmin=IGtable.min().min(), vmax=IGtable.max().max(), center = 0,\n",
    "           #row_linkage=hcRow, col_linkage=hcCol, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "        #    row_colors=[[\"red\",\"blue\"][int(l==\"B\")+0] for l in CV_sets[0][\"test\"][\"y\"].values]\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y])\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradient of \"+  str(numbFeatures)+ \" Best Features I-C weight 0.5\")\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig4_w05\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number_feat_perf_test = 25\n",
    "fig = shap.summary_plot(IG,  CV_sets_trainANDtest_X, max_display=numbFeatures , \n",
    "                  feature_names=ListFeatureColNames,cmap=\"seismic\", show = False)\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradients of Best Features with I-C weight 0.5\")\n",
    "figCommon = fileName_common + \"fig5_w05\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xcv = pd.DataFrame(CV_sets_trainANDtest_X, \n",
    "                     index=CV_sets_trainANDtest_y,\n",
    "                     columns=X.columns[modelD_FeaturesInt])\n",
    "\n",
    "fig6_feature_to_plot= ListFeatureColNames[0]\n",
    "\n",
    "shap.dependence_plot( fig6_feature_to_plot , IG, Xcv, show = False)\n",
    "\n",
    "figCommon = fileName_common + \"fig6_w05\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argsort(CV_sets[fold][\"test\"][\"y\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topFeaturesNumber = number_feat_perf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xtop3 = pd.DataFrame(CV_sets[fold][\"test\"][\"X\"][:,featRank_D[\"sorted\"][0:topFeaturesNumber ].astype(int)], \n",
    "#                      index=CV_sets[fold][\"test\"][\"y\"],\n",
    "#                      columns=X.columns[modelD_FeaturesInt])\n",
    "# IG = compute_SV_integrated_gradient(tesTune05[\"best_models\"][fold],\n",
    "#                                    CV_sets[fold][\"test\"][\"X\"][:,modelD_FeaturesInt])\n",
    "\n",
    "IGtable_wIndex = pd.DataFrame(IG, index=CV_sets_trainANDtest_y, columns=ListFeatureColNames)\n",
    "\n",
    "IGtable_wIndex.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(IGtable_wIndex.iloc[np.argsort(CV_sets_trainANDtest_y),:], \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=IGtable_wIndex.min().min(), vmax=IGtable_wIndex.max().max(), center = 0, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradients of \"+ str(numbFeatures) +' Best Features I-C weight 0.5')\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig7_w05\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_sets_trainANDtest_X = np.concatenate((CV_sets[fold][\"train\"][\"X\"][:,modelD_FeaturesInt],CV_sets[fold][\"test\"][\"X\"][:,modelD_FeaturesInt]), axis =0)\n",
    "# CV_sets_trainANDtest_y = np.concatenate((CV_sets[fold][\"train\"][\"y\"],CV_sets[fold][\"test\"][\"y\"]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counterfactuals = compute_counterfactuals(tunedModel[\"best_models\"][fold], \n",
    "                                          CV_sets_trainANDtest_X)\n",
    "CFtable = pd.DataFrame(counterfactuals, \n",
    "                       index=CV_sets_trainANDtest_y,columns=X.columns[modelD_FeaturesInt])\n",
    "\n",
    "CFtable.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(CFtable.iloc[np.argsort(CV_sets_trainANDtest_y),:],#/abs(Xtop3.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:]), \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=CFtable.min().min(), vmax=CFtable.max().max(), center =0,\n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "plt.suptitle(\"Train-Test Patients Counter factuals when training with \"+ str(numbFeatures) +' best features I-C weight 0.5')\n",
    "# plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig9_w05\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pickling the tesTune object\n",
    "# pickle_file = open('tesTune2_object_file', 'wb')\n",
    "# pickle.dump(tesTune2, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle_file_name = 'tesTune05_object_' + fileName_header +fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'wb')\n",
    "# pickle.dump(tesTune05, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter tuning for best features 0.75 weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelE_Features = featRank_E[\"best_features\"] #to get the best features which take highest score and highest C\n",
    "modelE_FeaturesInt = featRank_E[\"best_features\"].astype(int) #convert these to ints? to use as column finding for x.columns?\n",
    "modelE_numbFeatures = len(modelE_FeaturesInt) #number of features\n",
    "\n",
    "#list of column names\n",
    "modelE_FeaturesIntList = X.columns[featRank_E[\"best_features\"].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the parameters for the plots below\n",
    "featuresInt = modelE_FeaturesInt\n",
    "numbFeatures = modelE_numbFeatures\n",
    "ListFeatureColNames = modelE_FeaturesIntList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of classifier using the features found in ranking above\n",
    "#creation of tesTune_075\n",
    "tesTune075 = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range,feature_index=featuresInt)\n",
    "print(tesTune075[\"best_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling tesTune075\n",
    "pickle_file_name = 'tesTune075_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(tesTune075, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the tuned SVM model for the plots below\n",
    "tunedModel = tesTune075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature contribution plot using only the test data\n",
    "# feat_contribution = compute_SV_decision_perturbation(tunedModel[\"best_models\"][fold],CV_sets[fold][\"test\"][\"X\"][:,featuresInt])\n",
    "# FItable = pd.DataFrame(feat_contribution, index=CV_sets[fold][\"test\"][\"y\"],columns=ListFeatureColNames)\n",
    "\n",
    "# FItable.reset_index(drop=True, inplace=True)\n",
    "# fig = clustermap(FItable.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:], \n",
    "#            yticklabels=False,\n",
    "#            cmap=\"vlag\", vmin=-0.4, vmax=0.4,\n",
    "#            #row_linkage=hcRow, col_linkage=hcCol, \n",
    "#            row_cluster=False,col_cluster=False,\n",
    "#            cbar_pos=(1, .2, .03, .4),\n",
    "#            row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets[0][\"test\"][\"y\"].values[np.argsort(CV_sets[fold][\"test\"][\"y\"].values)]])\n",
    "# plt.suptitle(\"Test Patients Contribution when training with \"+  str(numbFeatures)+ \" best features I-C weight 0.75\")\n",
    "\n",
    "# figCommon = fileName_common + \"fig3_w075\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature contribution cluster map for all test and train patients\n",
    "CV_sets_trainANDtest_X = np.concatenate((CV_sets[fold][\"train\"][\"X\"][:,featuresInt],CV_sets[fold][\"test\"][\"X\"][:,featuresInt]), axis =0)\n",
    "CV_sets_trainANDtest_y = np.concatenate((CV_sets[fold][\"train\"][\"y\"],CV_sets[fold][\"test\"][\"y\"]), axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_contribution = compute_SV_decision_perturbation(tunedModel[\"best_models\"][fold],CV_sets_trainANDtest_X)\n",
    "# FItable = pd.DataFrame(feat_contribution, index=CV_sets_trainANDtest_y,columns=ListFeatureColNames)\n",
    "\n",
    "# FItable.reset_index(drop=True, inplace=True)\n",
    "# fig = clustermap(FItable.iloc[np.argsort(CV_sets_trainANDtest_y),:], \n",
    "#            yticklabels=False,\n",
    "#            cmap=\"vlag\", vmin=-0.4, vmax=0.4,\n",
    "#            #row_linkage=hcRow, col_linkage=hcCol, \n",
    "#            row_cluster=False,col_cluster=False,\n",
    "#            cbar_pos=(1, .2, .03, .4),\n",
    "#            row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "# plt.suptitle(\"Contribution test-train when training with best \"+  str(numbFeatures)+ \" features I-C weight 0.75\")\n",
    "\n",
    "# figCommon = fileName_common + \"fig3_2_w075\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrated gradient cluster map with heigharchical clustering\n",
    "\n",
    "IG = compute_SV_integrated_gradient(tunedModel[\"best_models\"][fold], CV_sets_trainANDtest_X)\n",
    "\n",
    "IGtable = pd.DataFrame(IG,columns=ListFeatureColNames)\n",
    "\n",
    "fig = clustermap(IGtable, \n",
    "           yticklabels=False,\n",
    "           cmap=\"vlag\", vmin=IGtable.min().min(), vmax=IGtable.max().max(), center = 0, \n",
    "           #row_linkage=hcRow, col_linkage=hcCol, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "        #    row_colors=[[\"red\",\"blue\"][int(l==\"B\")+0] for l in CV_sets[0][\"test\"][\"y\"].values]\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y])\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradient of \"+  str(numbFeatures)+ \" Best Features I-C weight 0.75\")\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig4_w075\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap plot for integrated gradients\n",
    "fig = shap.summary_plot(IG,  CV_sets_trainANDtest_X, max_display=numbFeatures , \n",
    "                  feature_names=ListFeatureColNames,cmap=\"seismic\", show = False)\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradients of Best Features with I-C weight 0.75\")\n",
    "figCommon = fileName_common + \"fig5_w075\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap dependence plot\n",
    "Xcv = pd.DataFrame(CV_sets_trainANDtest_X, \n",
    "                     index=CV_sets_trainANDtest_y,\n",
    "                     columns=ListFeatureColNames)\n",
    "\n",
    "fig6_feature_to_plot= ListFeatureColNames[0]\n",
    "\n",
    "shap.dependence_plot( fig6_feature_to_plot , IG, Xcv, show = False)\n",
    "\n",
    "figCommon = fileName_common + \"fig6_w075\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster map of integrated gradients sorted by index\n",
    "IGtable_wIndex = pd.DataFrame(IG, index=CV_sets_trainANDtest_y, columns=ListFeatureColNames)\n",
    "\n",
    "IGtable_wIndex.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(IGtable_wIndex.iloc[np.argsort(CV_sets_trainANDtest_y),:], \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=IGtable_wIndex.min().min(), vmax=IGtable_wIndex.max().max(), center = 0, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradients of \"+ str(modelE_numbFeatures) +' Best Features I-C weight 0.75')\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig7_w075\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter factuals map\n",
    "counterfactuals = compute_counterfactuals(tunedModel[\"best_models\"][fold], \n",
    "                                          CV_sets_trainANDtest_X)\n",
    "CFtable = pd.DataFrame(counterfactuals, \n",
    "                       index=CV_sets_trainANDtest_y,columns=ListFeatureColNames)\n",
    "\n",
    "CFtable.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(CFtable.iloc[np.argsort(CV_sets_trainANDtest_y),:],#/abs(Xtop3.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:]), \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=CFtable.min().min(), vmax=CFtable.max().max(), center =0, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "plt.suptitle(\"Train-Test Patients Counter factuals when training with \"+ str(numbFeatures) +' best features I-C weight 0.75')\n",
    "# plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig9_w075\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter tuning using list of best features from feature selection with only contribution featRank_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB_Features = featRank_B[\"best_features\"] #to get the best features which take highest score and highest C\n",
    "modelB_FeaturesInt = featRank_B[\"best_features\"].astype(int) #convert these to ints? to use as column finding for x.columns?\n",
    "modelB_numbFeatures = len(modelB_FeaturesInt) #number of features\n",
    "\n",
    "#list of column names\n",
    "modelB_FeaturesIntList = X.columns[featRank_B[\"best_features\"].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the parameters for the plots below\n",
    "featuresInt = modelB_FeaturesInt\n",
    "numbFeatures = modelB_numbFeatures\n",
    "ListFeatureColNames = modelB_FeaturesIntList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of classifier using the features found in ranking above\n",
    "#creation of tesTune_1\n",
    "tesTune100 = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range,feature_index=featuresInt)\n",
    "print(tesTune100[\"best_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling tesTune100\n",
    "pickle_file_name = 'tesTune100_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(tesTune100, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the tuned SVM model for the plots below\n",
    "tunedModel = tesTune100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature contribution plot using only the test data\n",
    "# feat_contribution = compute_SV_decision_perturbation(tunedModel[\"best_models\"][fold],CV_sets[fold][\"test\"][\"X\"][:,featuresInt])\n",
    "# FItable = pd.DataFrame(feat_contribution, index=CV_sets[fold][\"test\"][\"y\"],columns=ListFeatureColNames)\n",
    "\n",
    "# FItable.reset_index(drop=True, inplace=True)\n",
    "# fig = clustermap(FItable.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:], \n",
    "#            yticklabels=False,\n",
    "#            cmap=\"vlag\", vmin=-1, vmax=1,\n",
    "#            #row_linkage=hcRow, col_linkage=hcCol, \n",
    "#            row_cluster=False,col_cluster=False,\n",
    "#            cbar_pos=(1, .2, .03, .4),\n",
    "#            row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets[0][\"test\"][\"y\"].values[np.argsort(CV_sets[fold][\"test\"][\"y\"].values)]])\n",
    "# plt.suptitle(\"Test Patients Contribution when training with \"+  str(numbFeatures)+ \" best features contribution only\")\n",
    "\n",
    "# figCommon = fileName_common + \"fig3_w100\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature contribution cluster map for all test and train patients\n",
    "CV_sets_trainANDtest_X = np.concatenate((CV_sets[fold][\"train\"][\"X\"][:,featuresInt],CV_sets[fold][\"test\"][\"X\"][:,featuresInt]), axis =0)\n",
    "CV_sets_trainANDtest_y = np.concatenate((CV_sets[fold][\"train\"][\"y\"],CV_sets[fold][\"test\"][\"y\"]), axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_contribution = compute_SV_decision_perturbation(tunedModel[\"best_models\"][fold],CV_sets_trainANDtest_X)\n",
    "# FItable = pd.DataFrame(feat_contribution, index=CV_sets_trainANDtest_y,columns=ListFeatureColNames)\n",
    "\n",
    "# FItable.reset_index(drop=True, inplace=True)\n",
    "# fig = clustermap(FItable.iloc[np.argsort(CV_sets_trainANDtest_y),:], \n",
    "#            yticklabels=False,\n",
    "#            cmap=\"vlag\", vmin=-1.2, vmax=1.2,\n",
    "#            #row_linkage=hcRow, col_linkage=hcCol, \n",
    "#            row_cluster=False,col_cluster=False,\n",
    "#            cbar_pos=(1, .2, .03, .4),\n",
    "#            row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "# plt.suptitle(\"Contribution test-train when training with best \"+  str(numbFeatures)+ \" features contribution only\")\n",
    "\n",
    "# figCommon = fileName_common + \"fig3_2_w100\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrated gradient cluster map with heigharchical clustering\n",
    "\n",
    "IG = compute_SV_integrated_gradient(tunedModel[\"best_models\"][fold], CV_sets_trainANDtest_X)\n",
    "\n",
    "IGtable = pd.DataFrame(IG,columns=ListFeatureColNames)\n",
    "\n",
    "fig = clustermap(IGtable, \n",
    "           yticklabels=False,\n",
    "           cmap=\"vlag\", vmin=IGtable.min().min(), vmax=IGtable.max().max(), center =0, \n",
    "           #row_linkage=hcRow, col_linkage=hcCol, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "        #    row_colors=[[\"red\",\"blue\"][int(l==\"B\")+0] for l in CV_sets[0][\"test\"][\"y\"].values]\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y])\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradient of \"+  str(numbFeatures)+ \" Best Features contribution only\")\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig4_w100\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap plot for integrated gradients\n",
    "fig = shap.summary_plot(IG,  CV_sets_trainANDtest_X, max_display=numbFeatures , \n",
    "                  feature_names=ListFeatureColNames,cmap=\"seismic\", show = False)\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradients of Best Features with Contribution Only\")\n",
    "figCommon = fileName_common + \"fig5_w100\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap dependence plot\n",
    "Xcv = pd.DataFrame(CV_sets_trainANDtest_X, \n",
    "                     index=CV_sets_trainANDtest_y,\n",
    "                     columns=ListFeatureColNames)\n",
    "\n",
    "fig6_feature_to_plot= ListFeatureColNames[0]\n",
    "\n",
    "shap.dependence_plot( fig6_feature_to_plot , IG, Xcv, show = False)\n",
    "\n",
    "figCommon = fileName_common + \"fig6_w100\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster map of integrated gradients sorted by index\n",
    "IGtable_wIndex = pd.DataFrame(IG, index=CV_sets_trainANDtest_y, columns=ListFeatureColNames)\n",
    "\n",
    "IGtable_wIndex.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(IGtable_wIndex.iloc[np.argsort(CV_sets_trainANDtest_y),:], \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=IGtable_wIndex.min().min(), vmax=IGtable_wIndex.max().max(), center = 0, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "\n",
    "plt.suptitle(\"Train-Test Patients Integrated Gradients of \"+ str(numbFeatures) +' Best Features Contribution Only')\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig7_w100\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#counter factuals map\n",
    "counterfactuals = compute_counterfactuals(tunedModel[\"best_models\"][fold], \n",
    "                                          CV_sets_trainANDtest_X)\n",
    "CFtable = pd.DataFrame(counterfactuals, \n",
    "                       index=CV_sets_trainANDtest_y,columns=ListFeatureColNames)\n",
    "\n",
    "CFtable.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(CFtable.iloc[np.argsort(CV_sets_trainANDtest_y),:],#/abs(Xtop3.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:]), \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=CFtable.min().min(), vmax=CFtable.max().max(), center =0,\n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets_trainANDtest_y[np.argsort(CV_sets_trainANDtest_y)]])\n",
    "plt.suptitle(\"Train-Test Patients Counter factuals when training with \"+ str(numbFeatures) +' best features contribution only')\n",
    "# plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig9_w100\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcremerConda_2024-07-15_v1",
   "language": "python",
   "name": "mcremerconda_2024-07-15_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
