{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Implementation of Mistic \n",
    "to our binary description of patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/blue/ferrallm/mcremer/cardiac-amyloidosis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "starting_directory = os.getcwd()\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### libraries and dirrectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set dirrectory\n",
    "import os\n",
    "starting_directory = os.getcwd()\n",
    "\n",
    "#helps when fetching the functions and classes from mistic  \n",
    "# new_dirrectory = 'C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Shared-From-DrK/mistic_breast_cancer_example/mistic_breast_cancer_example'\n",
    "new_dirrectory = '/blue/ferrallm/mcremer/CardiacAmyloidosisMultipleMyeloma'\n",
    "os.chdir(new_dirrectory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatistics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean \n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m squareform\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linkage, dendrogram\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustermap, heatmap\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/spatial/__init__.py:110\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=============================================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m   QhullError\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/spatial/_kdtree.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Released under the scipy license\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminkowski_distance_p\u001b[39m(x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m_ckdtree.pyx:11\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/sparse/__init__.py:307\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    311\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    312\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    313\u001b[0m )\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/sparse/csgraph/__init__.py:187\u001b[0m\n\u001b[1;32m    158\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected_components\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    161\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaplacian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    162\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsgraph_to_masked\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    185\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegativeCycleError\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_laplacian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shortest_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    189\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson, yen,\n\u001b[1;32m    190\u001b[0m     NegativeCycleError\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traversal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    193\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    194\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    195\u001b[0m )\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_pydata_sparse_to_scipy, is_pydata_spmatrix\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/sparse/linalg/__init__.py:129\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dsolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlgmres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/sparse/linalg/_isolve/iterative.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_system\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicgstab\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqmr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_atol_rtol\u001b[39m(name, b_norm, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m):\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/linalg/__init__.py:207\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp_lu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp_ldl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp_cholesky\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/blue/ferrallm/mcremer/.conda/envs/mcremerConda_2024-07-15_v1/lib/python3.12/site-packages/scipy/linalg/_decomp_lu.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_misc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _datacopied, LinAlgWarning\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp_lu_cython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lu_dispatcher\n\u001b[1;32m     14\u001b[0m lapack_cast_dict \u001b[38;5;241m=\u001b[39m {x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfdFD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(x, y)])\n\u001b[1;32m     15\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtypecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     17\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlu_solve\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlu_factor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:645\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import packages/modules\n",
    "import matplotlib.pyplot as plt   \n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import mean \n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from seaborn import clustermap, heatmap\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "# Import functions\n",
    "from mistic_v1 import greedy_backward_selection, tuneSVM, compute_SV_feature_importance, compute_counterfactuals #, compute_SV_feature_contribution\n",
    "from mistic_v1 import compute_SV_gradient_rank2, compute_SV_importance_rank, compute_SV_contribution_rank, compute_SV_decision_perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy.stats import pearsonr\n",
    "from mistic_v1 import rank_items\n",
    "\n",
    "class SV_combined_rank():\n",
    "\n",
    "    def __init__(self,weight=0.5):\n",
    "        self.weight = weight\n",
    "\n",
    "    def compute(self,svc,X,y):\n",
    "        contribution_rank = compute_SV_contribution_rank(svc,X,y)\n",
    "        importance_rank = compute_SV_importance_rank(svc,X,y)\n",
    "\n",
    "        consensus_rank = self.weight*contribution_rank + (1-self.weight)*importance_rank\n",
    "        rank = rank_items(consensus_rank)\n",
    "        \n",
    "        return rank\n",
    "\n",
    "class svc_score():\n",
    "\n",
    "    def __init__(self, weight=0.5):\n",
    "        self.weight = weight\n",
    "\n",
    "    def score(self,svc,X,y):\n",
    "        y_pred = svc.predict(X)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "        if (tp+fp) > 0:\n",
    "            precision = tp/(tp+fp)\n",
    "        else:\n",
    "            precision = 0\n",
    "            \n",
    "        if (tp+fn) > 0:\n",
    "            recall = tp/(tp+fn)\n",
    "        else:\n",
    "            recall = 0\n",
    "        \n",
    "        if (precision+recall) > 0:\n",
    "            f1 = 2*precision*recall/(precision+recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "            \n",
    "        auc = roc_auc_score(y, svc.decision_function(X))\n",
    "        score = self.weight*auc + (1-self.weight)*f1\n",
    "            \n",
    "        return pd.DataFrame(data={'f1': f1, 'auc': auc, 'score': score},index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from mistic_v1 import compute_SV_integrated_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from seaborn import pairplot, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#some functions I wrote to help with exporting data\n",
    "def outputToExcel(df_data, fileName_header, fileName_Common, fileName_suffix,\n",
    "                  parent_dir, folderName, sheetName):\n",
    "    fileName = fileName_header + fileName_Common + fileName_suffix\n",
    "    outfile_extension = '.xlsx'\n",
    "    outfile_boxplts = fileName + outfile_extension\n",
    "    path_out= os.path.join(parent_dir, folderName, outfile_boxplts)\n",
    "\n",
    "    if os.path.exists(path_out):\n",
    "            #if old sheet\n",
    "            with pd.ExcelWriter(path_out, mode = 'a', if_sheet_exists = 'overlay') as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True)\n",
    "    else: \n",
    "            #new sheet\n",
    "            with pd.ExcelWriter(path_out) as writer:\n",
    "                    df_data.to_excel(writer, sheet_name = sheetName, index = True) #if new sheet\n",
    "    \n",
    "def outputFiguresPath(fileName_header, fileName_mid, fileName_suff, parent_dir, folderName):\n",
    "        fileName_header = str(fileName_header)\n",
    "        fileName_mid = str(fileName_mid)\n",
    "        fileName_suff = str(fileName_suff)\n",
    "\n",
    "        #cleaning the input to prevent addition of / to the directory\n",
    "        fileName_header = fileName_header.replace(\"/\", \"-\")\n",
    "        fileName_mid = fileName_mid.replace(\"/\", \"-\")\n",
    "        fileName_suff = fileName_suff.replace(\"/\", \"-\")\n",
    "\n",
    "        fileName = fileName_header + fileName_mid +fileName_suff\n",
    "        out_filename = fileName + '.tif'\n",
    "        new_filepath = os.path.join(parent_dir, folderName, out_filename)\n",
    "        #the output path can be used to save the figure\n",
    "        return new_filepath\n",
    "        # plt.savefig(new_filepath, bbox_inches = 'tight')\n",
    "\n",
    "def makeFolderPathForData(parent_dir, folderName_header, folderName_common, folderName_suffix):\n",
    "    #makes a new directory for your files\n",
    "    #returns the folder name for use in other functions\n",
    "    folderName = folderName_header + folderName_common + folderName_suffix\n",
    "    path = os.path.join(parent_dir,folderName)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return folderName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#consider changing dirrectory back to a space to save your data that isn't the mistic folder\n",
    "\n",
    "# new_dirrectory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/SVM_Mistic_Output_2024-07-12_v2\"\n",
    "# os.chdir(new_dirrectory)\n",
    "\n",
    "#for file outputs\n",
    "fileName_header = \"AllLabs_240716_fitRed05\" #what data did you put in\n",
    "fileName_common = \"_MisticOutput_\" #what was performed on the data, for figures, this may be added to\n",
    "fileName_suffix = \"_2024-07-22_v1\" #date and versioning\n",
    "\n",
    "# saving_dirrectory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/\"\n",
    "saving_dirrectory = \"012 Processed Data\"\n",
    "makingFolder = makeFolderPathForData(parent_dir= saving_dirrectory, folderName_header= \"SVM_Mistic_Output_AllLabs_05FitRed\", folderName_common= \"2024-07-22_\", \n",
    "                                     folderName_suffix= \"v1\")\n",
    "dataFrameFolderOut =  makingFolder #\"SVM_Mistic_Output_2024-07-19_v2\"\n",
    "pickleFolderOut = makingFolder\n",
    "\n",
    "figDirectory = \"012 Processed Data\"\n",
    "figFolder = makingFolder #\"SVM_Mistic_Output_2024-07-19_v2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#file name for inputs\n",
    "#file full with directory\n",
    "# fileInput_directory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/DFsForSVM_2024-07-12_v1/AL-KnownPts-top38labs-wFill-tx-Summary-One_2024-07-12_v1.xlsx\"\n",
    "fileInput_directory = 'AL-KnownPts-labsAll-wFill-tx-Summary-One_2024-07-16_v1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Import dataset\n",
    "\n",
    "dataTable = pd.read_excel(fileInput_directory, header = 0)\n",
    "dataTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#columns to drop from the x data (samples and features)\n",
    "x_columns_toDrop = ['DeID', 'Amyloid Status']\n",
    "\n",
    "\n",
    "#columns to use for the y data \n",
    "y_column_Classification = 'Amyloid Status'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale input X\n",
    "X = dataTable.copy()\n",
    "X.drop(columns= x_columns_toDrop,inplace=True)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X) #computes the mean and STD along the features axis\n",
    "\n",
    "X_train_all = scaler.transform(X) #standardization by centering and scaling\n",
    "y_train_all = dataTable[y_column_Classification]\n",
    "X_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the test and train sets \n",
    "pickle_file_name = 'X_train_all_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(X_train_all, pickle_file)\n",
    "\n",
    "pickle_file_name = 'y_train_all_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(y_train_all, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the scalar so that new data can be applied and mapped to use this classifier\n",
    "pickle_file_name = 'scaler_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(scaler, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading from pickled objects\n",
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'X_train_all_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# X_train_all = pickle.load(pickle_file)\n",
    "\n",
    "# #uploading the y train object\n",
    "# pickle_file_name = 'y_train_all_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# y_train_all = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of training sets\n",
    "NT = 5 \n",
    "\n",
    "# Data split ratio\n",
    "val_size = 1/NT\n",
    "\n",
    "#Feature selection reduction factor\n",
    "red_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split train set into train and test(val) data / repeat NT times and |get NT number of datsets\n",
    "CV_sets = []\n",
    "for i in range(NT):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_all, y_train_all, \n",
    "                                                        stratify = y_train_all, \n",
    "                                                        random_state= i, \n",
    "                                                        test_size= val_size)\n",
    "    \n",
    "    CV_set = {\"train\": {\"X\": X_train,\"y\": y_train}, \"test\":  {\"X\": X_test, \"y\": y_test}} \n",
    "    CV_sets.append(CV_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "C_range = [2**x for x in range(-2,5)] # trade-off between margin and misclassifications.  smaller c, wider margins\n",
    "gamma_range = [2**x for x in range(-9,1)]\n",
    "\n",
    "svc = SVC(kernel = 'rbf', class_weight=\"balanced\", probability=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tesTune, the first classifier using all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tesTune = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range)\n",
    "tesTune[\"best_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving the first test tune set\n",
    "perf = tesTune[\"performance\"]\n",
    "tesTune_best_params = tesTune[\"best_params\"]\n",
    "\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"tesTune perf\")\n",
    "outputToExcel(df_data=tesTune_best_params, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"tesTune best params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the tesTune object\n",
    "pickle_file_name = 'tesTune_object_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(tesTune, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'tesTune_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# tesTune = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesTune[\"best_models\"][0].classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## greedy_backward_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featRank_A fresh compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featRank_A = greedy_backward_selection(svc, X_train_all, CV_sets, compute_SV_importance_rank, svc_score().score, C_range, gamma_range, redF = red_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if not already pickled use this block\n",
    "pickle_file_name = 'featRankA_object_' + fileName_header + fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_A, pickle_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_A[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_A[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_A[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_A[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_A[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_A feature rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featRank_A upload from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankA_object_' + fileName_header +fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_A = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile featRank_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featRank_B = greedy_backward_selection(svc, X_train_all, CV_sets, compute_SV_contribution_rank, svc_score().score, C_range, gamma_range, redF = red_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankB_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_B, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_B[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_B[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_B[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_B[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_B[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_B feature rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load featRank_B from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankB_object_' + fileName_header +fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_B = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile featRank_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featRank_C = greedy_backward_selection(svc, X_train_all, CV_sets, SV_combined_rank(weight=0.25).compute, svc_score().score, C_range, gamma_range, redF = red_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankC_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_C, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_C[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_C[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_C[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_C[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_C[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_C feature rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upload featRank_C from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankC_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_C = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile featRank_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "featRank_D = greedy_backward_selection(svc, X_train_all, CV_sets, SV_combined_rank(weight=0.5).compute, svc_score().score, C_range, gamma_range, redF = red_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankD_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_D, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_D[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_D[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_D[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_D[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_D[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_D feature rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankD_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_D = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comple featRank_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featRank_E = greedy_backward_selection(svc, X_train_all, CV_sets, SV_combined_rank(weight=0.75).compute, svc_score().score, C_range, gamma_range, redF = red_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'featRankE_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(featRank_E, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the feature ranking, performance, and model evaluations to spreadsheets\n",
    "perf = featRank_E[\"performance\"]\n",
    "# perf\n",
    "outputToExcel(df_data=perf, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E performance\")\n",
    "\n",
    "df_columnNames_ranked = pd.DataFrame(list(X.columns[featRank_E[\"sorted\"].astype(int)]))\n",
    "#saving the column ranking\n",
    "outputToExcel(df_data=df_columnNames_ranked, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E col ranked\")\n",
    "\n",
    "df_bestFeatures= pd.DataFrame(list(X.columns[featRank_E[\"best_features\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestFeatures, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E best features\")\n",
    "\n",
    "df_bestModels= pd.DataFrame(featRank_E[\"best_models\"])\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_bestModels, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E best models\")\n",
    "\n",
    "df_Rank= pd.DataFrame(list(X.columns[featRank_E[\"rank\"].astype(int)]))\n",
    "#saving the best features\n",
    "outputToExcel(df_data=df_Rank, fileName_header=fileName_header, fileName_Common=fileName_common, fileName_suffix=fileName_suffix, parent_dir=saving_dirrectory,\n",
    "              folderName= dataFrameFolderOut, sheetName= \"featRank_E feature rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'featRankE_object_' + fileName_header + fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# featRank_E = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 4))\n",
    "plt.plot(featRank_A[\"performance\"].nFeats, featRank_A[\"performance\"].auc) \n",
    "plt.plot(featRank_C[\"performance\"].nFeats, featRank_C[\"performance\"].auc) \n",
    "plt.plot(featRank_D[\"performance\"].nFeats, featRank_D[\"performance\"].auc) \n",
    "plt.plot(featRank_E[\"performance\"].nFeats, featRank_E[\"performance\"].auc)\n",
    "plt.plot(featRank_B[\"performance\"].nFeats, featRank_B[\"performance\"].auc) \n",
    "\n",
    "plt.legend(['0','0.25','0.5','0.75','1'])\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving figure\n",
    "# figDirectory = \"C:/Users/maega/Documents/3000 PhD/3300_BEAT Labs/Projects/Cardiac-Amyloidosis-Multiple-Myeloma/012 Processed Data/\"\n",
    "# figFolder = \"SVM_Mistic_Draft_Output_2024-07-11_v1\"\n",
    "figCommon = fileName_common + \"fig1\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.tight_layout()\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 4))\n",
    "plt.plot(featRank_A[\"performance\"].nFeats, featRank_A[\"performance\"].f1) \n",
    "plt.plot(featRank_C[\"performance\"].nFeats, featRank_C[\"performance\"].f1) \n",
    "plt.plot(featRank_D[\"performance\"].nFeats, featRank_D[\"performance\"].f1) \n",
    "plt.plot(featRank_E[\"performance\"].nFeats, featRank_E[\"performance\"].f1) \n",
    "plt.plot(featRank_B[\"performance\"].nFeats, featRank_B[\"performance\"].f1) \n",
    "\n",
    "\n",
    "plt.legend(['0','0.25','0.5','0.75','1'])\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Number of features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figCommon = fileName_common + \"fig2\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input the top 3 features from your data set into the following plot for a 3D visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[featRank_D[\"sorted\"].astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listX = list(X.columns[featRank_D[\"sorted\"].astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(dataTable, x=listX[0], y=listX[1], z=listX[2],\n",
    "              color= y_column_Classification)\n",
    "fig.update_traces(marker_size = 4)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance outputs\n",
    "set the number of features you want to check the performance with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting number of features for performance test\n",
    "fold = 0\n",
    "number_feat_perf_test = 25 #describes for testing performance \n",
    "numb_features_figures = 5 #number of features to use in plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryText = \"nFeats == \" + str(number_feat_perf_test)\n",
    "# featRank_B[\"performance\"].query(queryText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {np.int64(1) :'red', np.int64(2): 'blue'} #our data is of int64\n",
    "featuresToPlot = list(X.columns[featRank_A[\"sorted\"].astype(int)][0:numb_features_figures])\n",
    "featuresToPlot.extend([y_column_Classification]) #must include the final classification column \n",
    "\n",
    "fig = pairplot(dataTable[featuresToPlot],hue= y_column_Classification, corner=True, palette=palette)\n",
    "# fig.title(\"featRank_A compare features\")\n",
    "\n",
    "figCommon = fileName_common + \"featRankA\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {np.int64(1) :'red', np.int64(2): 'blue'} #our data is of int64\n",
    "featuresToPlot = list(X.columns[featRank_B[\"sorted\"].astype(int)][0:numb_features_figures])\n",
    "featuresToPlot.extend([y_column_Classification]) #must include the final classification column \n",
    "\n",
    "fig = pairplot(dataTable[featuresToPlot],hue= y_column_Classification, corner=True, palette=palette)\n",
    "# fig.title(\"featRank_A 5 features\", loc = 'center')\n",
    "\n",
    "figCommon = fileName_common + \"featRankB_5\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryText = \"nFeats == \" + str(number_feat_perf_test)\n",
    "# featRank_E[\"performance\"].query(queryText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = {np.int64(1) :'red', np.int64(2): 'blue'} #our data is of int64\n",
    "featuresToPlot = list(X.columns[featRank_D[\"sorted\"].astype(int)][0:numb_features_figures])\n",
    "featuresToPlot.extend([y_column_Classification]) #must include the final classification column \n",
    "\n",
    "fig = pairplot(dataTable[featuresToPlot],hue= y_column_Classification, corner=True, palette=palette)\n",
    "# fig.title(\"featRank_A 5 features\", loc = 'center')\n",
    "\n",
    "figCommon = fileName_common + \"featRankD_5\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot(dataTable[['Area worst', 'Concave Points worst', 'Texture worst','Diagnosis']],hue=\"Diagnosis\", corner=True, palette={\"M\":\"red\",\"B\":\"blue\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesTune2 = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range,feature_index=featRank_D[\"sorted\"][0:10].astype(int))\n",
    "# tesTune2[\"best_params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pause here and evaluate block by block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameter tuning using the specified feature ranking and number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best model and number of features... use that model \n",
    "\n",
    "#filtering by max score\n",
    "maxscore = max(featRank_D[\"performance\"][\"score\"])\n",
    "queryText = \"score == \" + str(maxscore)\n",
    "# print(\"max score: \" , maxscore)\n",
    "# print(featRank_D[\"performance\"].query(queryText))\n",
    "\n",
    "# #filtering by max f1\n",
    "# maxF1 = max(featRank_D[\"performance\"][\"f1\"])\n",
    "# queryText = \"f1 == \" + str(maxF1) \n",
    "# print(\"max f1: \", maxF1) \n",
    "# print(featRank_D[\"performance\"].query(queryText))\n",
    "\n",
    "# #filtering by max auc\n",
    "# maxF1 = max(featRank_D[\"performance\"][\"auc\"])\n",
    "# queryText = \"auc == \" + str(maxF1) \n",
    "# print(\"max auc: \", maxF1) \n",
    "# print(featRank_D[\"performance\"].query(queryText))\n",
    "\n",
    "modelSelected = featRank_D[\"performance\"].query(queryText)\n",
    "numbfeatures = int(modelSelected[\"nFeats\"].iloc[0])\n",
    "# print(\"number of features: \", numbfeatures)\n",
    "# type(numbfeatures)\n",
    "\n",
    "number_feat_perf_test = numbfeatures\n",
    "numb_features_figures = numbfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickling the number of features and the best model\n",
    "pickle_file_name = 'modelSelected_performance_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(modelSelected, pickle_file)\n",
    "\n",
    "pickle_file_name = 'numbfeatures_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(numbfeatures, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to upload a pickled set use this block\n",
    "# pickle_file_name = 'modelSelected_performance_' + fileName_header +fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# modelSelected = pickle.load(pickle_file)\n",
    "\n",
    "# pickle_file_name = 'numbfeatures_object_' + fileName_header +fileName_suffix\n",
    "# pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "# pickle_file = open(pickle_filePath, 'rb')\n",
    "\n",
    "# #to put data into an object\n",
    "# numbfeatures = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# from mistic_v1 import compute_SV_integrated_gradient\n",
    "\n",
    "# fold = 0\n",
    "# number_feat_perf_test = 25\n",
    "tesTune2 = tuneSVM(svc, CV_sets, score_method = svc_score().score, costs = C_range, gammas = gamma_range,feature_index=featRank_D[\"sorted\"][0:number_feat_perf_test].astype(int))\n",
    "print(tesTune2[\"best_params\"])\n",
    "\n",
    "feat_contribution = compute_SV_decision_perturbation(tesTune2[\"best_models\"][fold],CV_sets[fold][\"test\"][\"X\"][:,featRank_D[\"sorted\"][0:number_feat_perf_test].astype(int)])\n",
    "FItable = pd.DataFrame(feat_contribution, index=CV_sets[fold][\"test\"][\"y\"],columns=X.columns[featRank_D[\"sorted\"][0:number_feat_perf_test].astype(int)])\n",
    "\n",
    "FItable.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(FItable.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:], \n",
    "           yticklabels=False,\n",
    "           cmap=\"vlag\", vmin=-2, vmax=2,\n",
    "           #row_linkage=hcRow, col_linkage=hcCol, \n",
    "           row_cluster=False,col_cluster=False,\n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets[0][\"test\"][\"y\"].values[np.argsort(CV_sets[fold][\"test\"][\"y\"].values)]])\n",
    "plt.suptitle(\"Contribution when Training with \"+  str(number_feat_perf_test)+ \" Features from featRank_D\")\n",
    "\n",
    "figCommon = fileName_common + \"fig3\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IG = compute_SV_integrated_gradient(tesTune[\"best_models\"][0], CV_sets[0][\"test\"][\"X\"])\n",
    "\n",
    "IGtable = pd.DataFrame(IG,columns=X.columns)\n",
    "\n",
    "fig = clustermap(IGtable, \n",
    "           yticklabels=False,\n",
    "           cmap=\"vlag\", vmin=-0.2, vmax=0.2,\n",
    "           #row_linkage=hcRow, col_linkage=hcCol, \n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "        #    row_colors=[[\"red\",\"blue\"][int(l==\"B\")+0] for l in CV_sets[0][\"test\"][\"y\"].values]\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets[0][\"test\"][\"y\"].values])\n",
    "plt.suptitle(\"Integrated Gradient Parameters\")\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig4\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_feat_perf_test = 25\n",
    "fig = shap.summary_plot(IG,  CV_sets[fold][\"test\"][\"X\"], max_display=number_feat_perf_test , \n",
    "                  feature_names=X.columns,cmap=\"seismic\", show = False)\n",
    "plt.suptitle(\"Integrated gradient Parameters\")\n",
    "figCommon = fileName_common + \"fig5\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xcv = pd.DataFrame(CV_sets[fold][\"test\"][\"X\"], \n",
    "#                      index=CV_sets[fold][\"test\"][\"y\"],\n",
    "#                      columns=X.columns)\n",
    "\n",
    "# shap.dependence_plot('ECOG Performance Status binary ', IG, Xcv, show = False)\n",
    "\n",
    "# figCommon = fileName_common + \"fig6\"\n",
    "# figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "# plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(CV_sets[fold][\"test\"][\"y\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topFeaturesNumber = number_feat_perf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtop3 = pd.DataFrame(CV_sets[fold][\"test\"][\"X\"][:,featRank_D[\"sorted\"][0:topFeaturesNumber ].astype(int)], \n",
    "                     index=CV_sets[fold][\"test\"][\"y\"],\n",
    "                     columns=X.columns[featRank_D[\"sorted\"][0:topFeaturesNumber ].astype(int)])\n",
    "IG = compute_SV_integrated_gradient(tesTune2[\"best_models\"][fold],\n",
    "                                   CV_sets[fold][\"test\"][\"X\"][:,featRank_D[\"sorted\"][0:topFeaturesNumber].astype(int)])\n",
    "\n",
    "IGtable = pd.DataFrame(IG, index=CV_sets[fold][\"test\"][\"y\"],columns=X.columns[featRank_D[\"sorted\"][0:topFeaturesNumber].astype(int)])\n",
    "\n",
    "IGtable.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(IGtable.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:], \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=-1.5, vmax=1.5,\n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets[fold][\"test\"][\"y\"].values[np.argsort(CV_sets[fold][\"test\"][\"y\"].values)]])\n",
    "\n",
    "plt.suptitle(\"Retrain with top \"+ str(topFeaturesNumber) +' features')\n",
    "plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig7\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.summary_plot(IG,  CV_sets[fold][\"test\"][\"X\"][:,featRank_D[\"sorted\"][0:topFeaturesNumber ].astype(int)], max_display=topFeaturesNumber , \n",
    "                  feature_names=X.columns[featRank_D[\"sorted\"][0:topFeaturesNumber ].astype(int)],cmap=\"seismic\", show = False)\n",
    "plt.suptitle(\"Training with top \"+ str(topFeaturesNumber) +' features')\n",
    "# plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig8\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "plt.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals = compute_counterfactuals(tesTune2[\"best_models\"][fold], \n",
    "                                          CV_sets[fold][\"test\"][\"X\"][:,featRank_D[\"sorted\"][0:topFeaturesNumber].astype(int)])\n",
    "CFtable = pd.DataFrame(counterfactuals, \n",
    "                       index=CV_sets[fold][\"test\"][\"y\"],columns=X.columns[featRank_D[\"sorted\"][0:topFeaturesNumber].astype(int)])\n",
    "\n",
    "CFtable.reset_index(drop=True, inplace=True)\n",
    "fig = clustermap(CFtable.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:],#/abs(Xtop3.iloc[np.argsort(CV_sets[fold][\"test\"][\"y\"].values),:]), \n",
    "           yticklabels=False,\n",
    "           col_cluster=False,\n",
    "           row_cluster=False,\n",
    "           cmap=\"vlag\", vmin=-1.5, vmax=1.5,\n",
    "           cbar_pos=(1, .2, .03, .4),\n",
    "           row_colors=[[\"red\",\"blue\"][int(l==np.int64(1))+0] for l in CV_sets[fold][\"test\"][\"y\"].values[np.argsort(CV_sets[fold][\"test\"][\"y\"].values)]])\n",
    "plt.suptitle(\"Counter factuals when training with top \"+ str(topFeaturesNumber) +' features')\n",
    "# plt.show()\n",
    "\n",
    "figCommon = fileName_common + \"fig9\"\n",
    "figPath = outputFiguresPath(fileName_header=fileName_header, fileName_mid= figCommon, fileName_suff= fileName_suffix, parent_dir= figDirectory, folderName= figFolder)\n",
    "fig.savefig(figPath, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pickling the tesTune object\n",
    "# pickle_file = open('tesTune2_object_file', 'wb')\n",
    "# pickle.dump(tesTune2, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_name = 'tesTune2_object_' + fileName_header +fileName_suffix\n",
    "pickle_filePath = os.path.join(saving_dirrectory, pickleFolderOut, pickle_file_name)\n",
    "pickle_file = open(pickle_filePath, 'wb')\n",
    "pickle.dump(tesTune2, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcremerConda_2024-07-15_v1",
   "language": "python",
   "name": "mcremerconda_2024-07-15_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
